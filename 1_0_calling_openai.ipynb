{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cf19000-f241-4095-8bc1-8f8e14fc34a8",
   "metadata": {
    "id": "2cf19000-f241-4095-8bc1-8f8e14fc34a8"
   },
   "source": [
    "On commence par expérimenter les calls API des modèles d'OpenAI.\n",
    "\n",
    "On a stocké dans le fichier `keys.py` notre clef API de OpenAI, qui nous permet de faire des requêtes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eMyppwFks-Jf",
   "metadata": {
    "id": "eMyppwFks-Jf"
   },
   "source": [
    "Installons les packages nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a3c0383-6c92-4e0d-a6cf-c5ccaf5277f1",
   "metadata": {
    "id": "6a3c0383-6c92-4e0d-a6cf-c5ccaf5277f1",
    "outputId": "e9cdaf3b-fb6d-49c1-9319-108c3a617e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.12/site-packages (1.51.2)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.12/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/conda/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.12/site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.12/site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec9e878-2e5a-49e7-8cd7-c3c96b9fcbce",
   "metadata": {
    "id": "aec9e878-2e5a-49e7-8cd7-c3c96b9fcbce"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import tiktoken  # librairie de OpenAI\n",
    "\n",
    "from LLMPlayplace.credentials.keys import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7220f9f3-4643-43fc-a0e5-7635fdb9968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMPlayplace\n"
     ]
    }
   ],
   "source": [
    "! ls "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sz3YHrsHtBtn",
   "metadata": {
    "id": "sz3YHrsHtBtn"
   },
   "source": [
    "# 1) Utiliser OpenAI pour les embeddings de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26f78d4-83d5-4783-b3c6-6f2f537f5578",
   "metadata": {
    "id": "e26f78d4-83d5-4783-b3c6-6f2f537f5578"
   },
   "source": [
    "La liste des modèles disponibles via l'API d'OpenAI est disponible [ici](https://platform.openai.com/docs/models). En particulier, 3 [modèles d'embedding](https://platform.openai.com/docs/models/embeddings) sont disponibles.\n",
    "\n",
    "Sélectionnons le plus basique, `text-embedding-ada-002`, et commençons par jouer avec les embeddings de mots, pour illustrer notamment \"king - queen\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2937116b-36d8-4471-8501-9fdab68b659f",
   "metadata": {
    "id": "2937116b-36d8-4471-8501-9fdab68b659f",
    "outputId": "8c20200d-3dd6-43aa-e53c-13f47b1e0ac8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.create_embedding_response.CreateEmbeddingResponse'>\n"
     ]
    }
   ],
   "source": [
    "# On prépare un client pour appeler l'API d'OpenAI.\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "mot = 'queen'\n",
    "\n",
    "# Make the API call to the embedding endpoint\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=mot\n",
    ")\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf87b1-29a6-4b80-81e4-58ee10268573",
   "metadata": {
    "id": "66cf87b1-29a6-4b80-81e4-58ee10268573"
   },
   "source": [
    "La réponse est un objet **openai** avec plusieurs attributs intéressants : **`response.usage`** et **`response.data`**.\n",
    "\n",
    " * `response.usage` nous informe sur le coût en termes de tokens de notre requête\n",
    "\n",
    " * `response.data` contient l'embedding qui nous intéresse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af03d3a-0e50-441b-a197-0a36cfd381b1",
   "metadata": {
    "id": "8af03d3a-0e50-441b-a197-0a36cfd381b1",
    "outputId": "c0dc246b-809b-4b9a-db12-8efa2f3fe244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage(prompt_tokens=1, total_tokens=1)\n"
     ]
    }
   ],
   "source": [
    "print(response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5feab0-2fbd-4bc8-853f-5b4d0682e39e",
   "metadata": {
    "id": "ea5feab0-2fbd-4bc8-853f-5b4d0682e39e"
   },
   "source": [
    "Plus précisement, l'objet `response` contient une liste d'objets **Embedding**, chacun ayant un attribut `embedding` qui contient notre vecteur d'embeddings sous forme de liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b80fedaa-892a-4cec-b3b9-9f9e7d022c1a",
   "metadata": {
    "id": "b80fedaa-892a-4cec-b3b9-9f9e7d022c1a",
    "outputId": "1c0aa543-9846-405d-e9d7-632e1d57c718",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.004559878259897232, -0.006745691876858473, -0.002501309383660555, -0.018281348049640656, -0.01691477932035923, 0.010472381487488747, -0.00765557587146759, -0.02404046058654785, -0.017319170758128166, -0.012905711308121681, 0.01447447668761015, 0.02232527732849121, 0.01455814391374588, -0.0029876267071813345, -0.01878335326910019, 0.008889671415090561, 0.04328398406505585, 0.021056318655610085, 0.02953462488949299, -0.008861782029271126, 0.002075999742373824, 0.014139806851744652, -0.005400039721280336, 0.003615132998675108, -0.005347747355699539, -0.010158628225326538, 0.007286044303327799, -0.005574346985667944, 0.0015173448482528329, -0.01549243088811636, 0.00952414982020855, 0.006194880697876215, -0.02370578981935978, -0.015617932192981243, -0.024974746629595757, -0.008931505493819714, 0.009008199907839298, 0.0016036269953474402, -0.011469419114291668, -0.005588291212916374, 0.007320906035602093, 0.010332935489714146, 0.00011068512685596943, 0.021823272109031677, -0.0015583070926368237, 0.0056092082522809505, -0.01685900054872036, -0.02023358829319477, 0.0033222967758774757, 0.006146074738353491, 0.016886889934539795, -0.0009761207620613277, -0.022283442318439484, -0.001522574108093977, -0.02193482778966427, -0.008875726722180843, -0.015659766271710396, 0.005741681903600693, 0.0004492770240176469, 0.007174487691372633, 0.010054044425487518, 0.008248220197856426, -0.004315848462283611, 0.010709439404308796, 0.0007639016839675605, -0.005459303967654705, -0.022171886637806892, 0.015910768881440163, -0.0019522415241226554, 0.0015818385872989893, 0.030036630108952522, 0.02579747699201107, 0.017221558839082718, 0.0017474305350333452, 0.00896636676043272, -0.054885875433683395, -0.019173800945281982, 0.017584118992090225, 0.006571384612470865, 0.00783685501664877, 0.014516310766339302, -0.009586900472640991, -0.016831111162900925, 0.00020818825578317046, 0.008450416848063469, 0.010479353368282318, -0.022408943623304367, 0.010904663242399693, -0.003088725032284856, 0.0054697622545063496, 0.018225569278001785, 0.01386091485619545, 0.019731584936380386, 0.03424789384007454, -0.019815251231193542, 0.011567031033337116, 0.0149904265999794, 0.04074607044458389, -0.0008554129744879901, -0.020219644531607628, 0.028433004394173622, 0.01479520183056593, -0.039267946034669876, -0.016607997938990593, -0.011894728988409042, -0.01174831110984087, -0.02236711047589779, -0.013707524165511131, 0.00882692076265812, 0.016315162181854248, -0.024416964501142502, 0.0216838251799345, 0.018476571887731552, -0.04576611891388893, 0.00829702615737915, -0.024695856496691704, -0.009321953170001507, 0.0042844731360673904, 0.00044382992200553417, -0.029729850590229034, 0.024207795038819313, 0.011204471811652184, 0.028697950765490532, -0.012536179274320602, 0.004476211033761501, 0.0136238569393754, -0.0015086295315995812, -0.019034355878829956, -0.008129691705107689, 0.014544199220836163, 0.03408056125044823, 0.014335030689835548, 0.02397073805332184, 0.002375808311626315, -0.011357862502336502, 0.00797630101442337, -0.022520501166582108, -0.0029928560834378004, 0.008485278114676476, -0.019550304859876633, -0.02034514583647251, 0.038124486804008484, -0.019076189026236534, -0.005169954150915146, -0.003730175783857703, 0.017598062753677368, 0.0021038888953626156, 0.02408229373395443, -0.0015121157048270106, 0.01531115174293518, 0.01974552869796753, -0.0036360498052090406, 0.029562514275312424, -0.020373035222291946, 0.03352277725934982, 0.013024239800870419, 0.003939344547688961, -0.0018842617282643914, -0.005162981804460287, -0.007509157527238131, 0.015101983211934566, 0.007383656222373247, 0.02044275775551796, -0.02093081921339035, 0.008087857626378536, 0.017584118992090225, 0.022060329094529152, 0.015771321952342987, 0.0011016220087185502, -0.00550113758072257, -0.008931505493819714, 0.012703514657914639, -0.022827280685305595, 0.008317943662405014, 0.005717278923839331, 0.027373215183615685, 0.015994437038898468, -0.0043053897097706795, 0.007069903425872326, -0.006522578652948141, -0.02832144685089588, 0.011099888011813164, 0.013616885058581829, 0.015813156962394714, -0.021600158885121346, 0.02783338725566864, 0.009029117412865162, -0.015701599419116974, 0.032937102019786835, -0.03474989905953407, 3.9110196667024866e-05, 0.012222426943480968, 0.026076368987560272, -0.0253651961684227, -0.6711248755455017, -0.019717639312148094, -0.0020725135691463947, -0.006707344204187393, 0.015562154352664948, 0.0030242314096540213, 0.023914959281682968, 0.00829702615737915, -0.007613742258399725, -0.018504461273550987, -0.008840865455567837, -0.005455818027257919, -0.0046888659708201885, 0.003970719873905182, -0.01595260202884674, -0.017430728301405907, -0.01830923743546009, -0.030845416709780693, 0.0014911987818777561, 0.01511592697352171, 0.012452512048184872, 0.005187384784221649, -0.003768523456528783, 0.010019182227551937, 0.013365882448852062, 0.008408583700656891, 0.004877117928117514, -0.0042844731360673904, -0.005780029576271772, 0.007045500446110964, -0.023385064676404, 0.024068349972367287, 0.010339908301830292, 0.0015356471994891763, 0.02247866615653038, 0.0006122543127276003, -0.014014305546879768, 0.03505668044090271, 0.009440482594072819, 0.028014665469527245, -0.021879049018025398, -0.001417989726178348, 0.009405621327459812, -0.024807412177324295, 0.013205519877374172, 0.015506375581026077, -0.0004211699706502259, 0.008415555581450462, -0.002028936753049493, 0.012215454131364822, -0.0008985540480352938, 0.0032177125103771687, 0.0047690472565591335, 0.02017781138420105, -0.010130738839507103, 0.002964966930449009, 0.0363953597843647, -0.0025257125962525606, -0.004085762891918421, -0.008039051666855812, 0.010291101410984993, -0.002877813298255205, -0.01717972569167614, -0.017040280625224113, -0.006930457428097725, 0.014669700525701046, -0.006118185352534056, -0.007327877916395664, 0.008736280724406242, -0.030371300876140594, 0.0019086647080257535, 0.010702467523515224, 0.00046322160051204264, 0.006198367103934288, -7.184728019637987e-05, 0.035670243203639984, 0.0221579410135746, -0.006480744574218988, -0.03145897760987282, -0.0066689965315163136, 0.02081926167011261, -0.014244390651583672, -0.00952414982020855, 0.009029117412865162, 0.024207795038819313, -0.029255734756588936, -0.03388533368706703, 0.02681543119251728, 0.010751273483037949, 0.005933419801294804, 0.01525537297129631, 0.005535999312996864, -0.0006789268809370697, -0.02392890304327011, 0.019299302250146866, 0.02093081921339035, -0.007094306405633688, 0.0011129520135000348, 0.024877134710550308, -0.04317242652177811, 0.005549944005906582, -0.006376160308718681, 0.007418517954647541, 0.002830750308930874, 0.017584118992090225, 0.0091476459056139, -0.011141721159219742, 0.02402651496231556, 0.04088551551103592, -0.0182952918112278, -0.0017709620296955109, 0.006498175207525492, -0.0015321610262617469, -0.010074960999190807, -0.0012794154463335872, -0.031654201447963715, 0.011915645562112331, 0.025295471772551537, 0.0032926646526902914, -0.0011460704263299704, 0.022994617000222206, 0.001476382720284164, 0.005905530881136656, -0.025978757068514824, 0.00029414353775791824, 0.015562154352664948, -0.0028150626458227634, -0.0022137025371193886, -0.021488601341843605, 0.01153216976672411, 0.027205880731344223, -0.005480221007019281, 0.013909720815718174, -0.008945449255406857, 0.01605021394789219, -0.01262681931257248, 0.027331382036209106, -0.0023810374550521374, 0.02279939316213131, 0.014188612811267376, 0.0016533045563846827, -0.01105108205229044, -0.009440482594072819, 0.011790144257247448, -0.01595260202884674, -0.011434557847678661, 0.000599181279540062, -0.015854990109801292, -0.01867179572582245, 0.019675806164741516, -0.003768523456528783, -0.0021422365680336952, 0.0019138939678668976, 0.031933095306158066, 0.015799211338162422, -0.023482676595449448, -0.015603987500071526, -0.008548028767108917, -0.008303998969495296, -0.0012393248034641147, 0.01814190112054348, -0.007090819999575615, -0.026773598045110703, -0.018100067973136902, -0.0016306446632370353, -0.022297387942671776, 0.014070083387196064, 0.012633792124688625, -0.007230265997350216, -0.029144177213311195, 0.009475343860685825, -0.023371120914816856, -0.004720241297036409, 0.012027202174067497, 0.023106172680854797, 0.006118185352534056, 0.011448502540588379, 0.008046024478971958, -0.0021945287007838488, -0.008401610888540745, 0.019201690331101418, -0.017807232216000557, -0.03617224842309952, -0.017221558839082718, 0.032351430505514145, 0.01846262812614441, -0.006557439919561148, 0.010939524509012699, -0.024110183119773865, -0.01447447668761015, -0.005727737210690975, 0.010012210346758366, -0.0053442614153027534, -0.028391169384121895, -0.013846970163285732, -0.02113998681306839, -0.002720936667174101, 0.02670387551188469, 0.0028621256351470947, 0.006961832754313946, 0.01680322177708149, -0.012243343517184258, 0.02430540695786476, -0.0017918788362294436, 0.001500785700045526, -0.042893536388874054, 0.01099530328065157, -0.012801126576960087, 0.05020049586892128, 0.013895776122808456, 0.0253651961684227, -0.013310103677213192, -0.0006885137408971786, -0.0033240397460758686, 0.01584104634821415, 0.013658718205988407, 0.007362739648669958, 0.010820996016263962, 0.007523102220147848, -0.01744467206299305, -0.009893680922687054, -0.008743253536522388, -0.01846262812614441, 0.01804428920149803, 0.00976817961782217, 0.004957299213856459, 0.018058234825730324, 0.003914941567927599, 0.01642671786248684, -0.0007146598654799163, -0.007725298870354891, -0.01370055228471756, -0.030315522104501724, 0.010639716871082783, -0.009914598427712917, 0.02012203261256218, 0.034973014146089554, -0.0142374187707901, 0.0226320568472147, -0.005316372029483318, -0.003866135608404875, 0.030176077038049698, 0.011539141647517681, -0.01851840503513813, 0.01738889515399933, -0.0013552390737459064, 0.03179364651441574, 0.0216838251799345, -0.009461399167776108, 0.005863696802407503, -0.011755282990634441, -0.012278204783797264, -0.019090132787823677, -0.001812795759178698, 0.007516129873692989, -0.019871030002832413, 0.014837035909295082, 0.021920884028077126, 0.02493291348218918, 0.029367290437221527, 0.006316896062344313, 0.005441873334348202, -0.007990245707333088, 0.020916873589158058, 0.027554495260119438, -0.0031462463084608316, 0.03296499326825142, 0.005407012067735195, -0.005239676684141159, -0.011176582425832748, 0.002370578935369849, -0.01953635923564434, 0.01637093909084797, -0.01145547442138195, 0.00821335893124342, -0.023803401738405228, -0.027387160807847977, 0.0033344982657581568, 0.0024856217205524445, -0.002879556268453598, -0.0021370071917772293, -0.03483356535434723, 0.018211625516414642, -0.0004680150595959276, -0.009552039206027985, -0.028237778693437576, -0.007781077176332474, -0.007920523174107075, -0.00670385779812932, 0.025546474382281303, 0.012117842212319374, 0.010667605325579643, -0.00834583304822445, 0.00038064352702349424, -0.0118319783359766, -0.006111213471740484, 0.018755463883280754, -0.011190527118742466, -0.003608160652220249, 0.007038528099656105, -0.015562154352664948, -0.009907625615596771, -0.019564248621463776, 0.0018371987389400601, 0.024709800258278847, -0.009008199907839298, -0.011978396214544773, -0.023189840838313103, -0.006501661613583565, -0.01765384152531624, 0.007017611060291529, -0.0004414331924635917, -0.01217362005263567, 0.004085762891918421, 0.00968451239168644, 0.007920523174107075, -0.015352984890341759, -0.015060149133205414, 0.035726021975278854, -0.0148509806022048, -0.01067457813769579, -0.024389075115323067, -0.010067988187074661, -0.005462790373712778, 0.10067988187074661, -0.017570173367857933, -0.0007421132759191096, -0.008039051666855812, -0.026745708659291267, -0.011608865112066269, -0.011657671071588993, -0.012243343517184258, 0.0062890066765248775, -0.011058053933084011, 0.003817329416051507, -0.006411021575331688, -0.004796936176717281, 0.018155846744775772, 0.015603987500071526, 0.021098153665661812, -0.0064284526742994785, -0.02794494293630123, 0.004239153116941452, -0.0005089772748760879, -0.012975433841347694, -0.012815071269869804, 0.018183736130595207, 0.014376864768564701, -0.006961832754313946, -0.012759293429553509, 0.016831111162900925, 0.037064701318740845, 0.025183916091918945, -0.02734532579779625, 0.004793450236320496, 0.006522578652948141, -0.00394631689414382, 0.012689569965004921, 0.0030608358792960644, 0.010904663242399693, 0.00626111775636673, -0.005661500617861748, 0.014697589911520481, -0.01067457813769579, 0.02129337750375271, 0.018225569278001785, 0.009301036596298218, -0.018476571887731552, 0.019062243402004242, -0.0226320568472147, 0.0010963927488774061, 0.013742386363446712, 0.006578356958925724, -0.021697770804166794, 0.06308528780937195, 0.007202377077192068, -0.021098153665661812, -0.018127957358956337, 0.00837372150272131, 0.009970376268029213, 0.0029614807572215796, -0.0086735300719738, -0.00912672933191061, 0.018908854573965073, -0.0190482996404171, -0.013010295107960701, 0.0110789705067873, 0.010067988187074661, 0.011880784295499325, -0.021335210651159286, -0.010862830094993114, -0.005253621377050877, 0.0034338533878326416, -0.009496260434389114, -0.017305226996541023, -0.01394458208233118, -0.009642679244279861, 0.009865792468190193, -0.0034094504080712795, 0.013526245020329952, 0.005902044475078583, -0.014307141304016113, 0.012884793803095818, 0.025114193558692932, -7.914639718364924e-05, -0.0324351005256176, -0.015366929583251476, -0.032407209277153015, -0.018922798335552216, -0.0043088761158287525, -0.00966359581798315, -0.018908854573965073, -0.017598062753677368, 0.00046845083124935627, 0.026397094130516052, -0.01733311638236046, 0.021056318655610085, -0.0023688359651714563, -0.010207434184849262, -0.006533036939799786, 0.014335030689835548, 0.01298240665346384, -0.011622809804975986, 0.008764170110225677, 0.016566164791584015, -0.043005093932151794, -0.0032299140002578497, -0.006017087493091822, 0.015603987500071526, 0.0019679293036460876, 0.0062646036967635155, 0.0170681681483984, -0.0002575390099082142, -0.000569984782487154, 0.004110165871679783, -0.033801667392253876, -0.005291969049721956, -0.008248220197856426, -0.00787171721458435, 0.006390105001628399, -0.009496260434389114, 0.018392903730273247, 0.011009247973561287, -0.005225732456892729, -0.0015861962456256151, -0.029506737366318703, 0.04730002209544182, 0.014864925295114517, -0.02236711047589779, 0.008310970850288868, -0.00976817961782217, 0.007195404730737209, -0.012340955436229706, 0.013226436451077461, 0.0110789705067873, 0.01670560985803604, 0.002755798166617751, -0.0124455401673913, -0.017096057534217834, -0.010186517611145973, -0.021153932437300682, 0.006278548389673233, -0.0031584480311721563, -0.01642671786248684, -0.04314453899860382, -0.001240196288563311, 0.005818377248942852, -0.04320031777024269, -0.012884793803095818, -0.04392543435096741, 0.003198538674041629, 0.014167696237564087, -0.01867179572582245, 0.004043928813189268, -0.01712394692003727, -0.004242639057338238, -0.004566850606352091, 0.0026146091986447573, -0.006822386756539345, -0.028865285217761993, -0.03949105739593506, 0.0015095010166987777, 0.011922618374228477, 0.01447447668761015, 0.024389075115323067, 0.012103897519409657, 0.010932552628219128, -0.004406488034874201, 0.01177619956433773, -0.010946497321128845, -0.0042042918503284454, -0.02161410264670849, -0.009782124310731888, 0.01370055228471756, 0.003270004643127322, 0.01825345866382122, -0.0007268613553605974, 0.014376864768564701, -0.02332928590476513, 0.014049166813492775, -0.019173800945281982, -0.01680322177708149, -0.013665691018104553, -0.010904663242399693, -0.008952422067523003, 0.0010763474274426699, -0.02953462488949299, 0.01605021394789219, 0.00711870938539505, 0.00315670482814312, 0.02525363862514496, -0.00024490171927027404, 0.01895068772137165, 0.0006950502865947783, 0.016301216557621956, -0.025169970467686653, 0.0182952918112278, -0.010228351689875126, 0.001485969522036612, -0.0002268173557240516, -7.768930117890704e-06, 0.015185650438070297, -0.010451464913785458, 0.01770962029695511, 0.009154618717730045, 0.008094830438494682, -0.005382608622312546, 0.010193489491939545, -0.01563187688589096, 0.013972471468150616, -2.4362165277125314e-05, -0.021586213260889053, 0.009489288553595543, -0.04085762798786163, -0.008492250926792622, -0.010925580747425556, -0.010500270873308182, -0.04537567123770714, -8.426667773164809e-05, 0.020540369674563408, -0.014906758442521095, 0.01702633500099182, -0.011943534947931767, -0.024556409567594528, 0.01840684935450554, 0.0040299841202795506, 0.011601892299950123, -0.019898919388651848, 0.032686103135347366, 0.01964791677892208, 1.2644086382351816e-05, 0.008220331743359566, 0.014118889346718788, -0.02889317460358143, -0.02028936706483364, 0.008945449255406857, 0.02231133170425892, 0.008366749621927738, -0.006494689267128706, 0.015799211338162422, -0.0067282612435519695, -0.03522401675581932, -0.018323181197047234, 0.025713810697197914, 0.017570173367857933, -0.0017883926630020142, 0.0012523977784439921, -0.004242639057338238, -0.01370055228471756, 0.005427928641438484, -0.008924532681703568, -0.010130738839507103, -0.027972832322120667, -0.006686427164822817, -0.0029196469113230705, 0.00031898231827653944, 0.004894548561424017, 0.0010484582744538784, -0.009384703822433949, -0.018169790506362915, 0.0053895809687674046, -0.01642671786248684, -0.012675625272095203, -0.0027854302898049355, -0.0403556227684021, 0.03452678769826889, -0.03271399065852165, 0.00781593844294548, -0.0085340840741992, -0.012564068660140038, -0.026522595435380936, -0.013595967553555965, -0.012661680579185486, 0.031124308705329895, -0.007369711995124817, 0.01942480355501175, 0.0059090168215334415, -0.008317943662405014, 0.010730355978012085, -0.007411545608192682, -0.013038184493780136, -0.022032439708709717, -0.0005817505298182368, -0.026201870292425156, 0.001339551410637796, 0.012048119679093361, 0.0011112089268863201, -0.023189840838313103, -0.014753368683159351, -0.017319170758128166, -0.007146598305553198, -0.0045494199730455875, 0.005016563460230827, -0.0030399190727621317, -0.007258155383169651, 0.0061286441050469875, -0.001449365052394569, 0.02596481330692768, 0.02012203261256218, -0.012201509438455105, 0.0026006647385656834, 0.013547161594033241, -0.015185650438070297, 0.0292278453707695, -0.018183736130595207, -0.013575050979852676, -0.009168563410639763, -0.012773237191140652, 0.012410677969455719, -0.025560420006513596, 0.019871030002832413, -0.021321266889572144, -0.0019574707839637995, 0.0018703171517699957, -0.02339901030063629, 0.00699669448658824, -0.00017158372793346643, -0.00898728333413601, 0.001164372661150992, 0.00829702615737915, -0.013742386363446712, -0.02500263601541519, -0.02087504044175148, 0.022116107866168022, 0.0008323172805830836, 0.013512300327420235, 0.010486326180398464, -0.0068851374089717865, -0.008736280724406242, 0.00842950027436018, 0.01036082487553358, 0.015506375581026077, -0.025407029315829277, -0.007697409484535456, -0.04320031777024269, 0.015478486195206642, -0.0026424983516335487, -0.02268783561885357, -0.005612694658339024, -0.018699685111641884, -0.005396553315222263, 0.028781618922948837, -0.012424622662365437, -0.009747263044118881, 0.012222426943480968, 0.02858639322221279, 0.023733679205179214, 0.01020046230405569, 0.001712569035589695, -0.00904306210577488, 0.0030608358792960644, -0.011260250583291054, -0.017054224386811256, -0.003705772804096341, -0.0039498028345406055, 0.020526425912976265, 0.002285168506205082, -0.04105285182595253, -0.028293557465076447, 0.0014319343026727438, -0.033913224935531616, -0.004626115318387747, -0.020902929827570915, 0.02451457642018795, -0.007122195325791836, 0.0032177125103771687, -0.003991636913269758, 0.008185469545423985, -0.01691477932035923, -0.0037894402630627155, -0.027484772726893425, -0.001780548831447959, -0.00038391179987229407, -0.026731764897704124, -0.0019400400342419744, -0.011762254871428013, -0.02429146319627762, -0.0020603120792657137, 0.03553079441189766, 0.007327877916395664, -0.009803041815757751, 0.038403380662202835, -0.0024943372700363398, -0.007550991605967283, -0.0024350727908313274, 0.0178211759775877, 0.026899099349975586, 0.011350889690220356, 0.021432822570204735, -0.018908854573965073, -0.0005852367030456662, 0.03402478247880936, 0.01584104634821415, -0.01787695474922657, -0.011657671071588993, 0.009921570308506489, -0.012299121357500553, 0.01083494070917368, -0.014049166813492775, 0.002075999742373824, 0.00029632236692123115, -0.025922978296875954, 0.008283082395792007, 0.000733397901058197, -0.010925580747425556, 0.0341363362967968, -0.03221198543906212, -0.015757378190755844, -0.00290395924821496, -0.004403002094477415, -0.00226076552644372, 0.0007887404644861817, 0.02151649072766304, -0.013693580403923988, 0.0026808460243046284, -0.011343917809426785, 0.012103897519409657, -0.016621941700577736, 0.006135616451501846, 0.00858986284583807, -0.0006231485167518258, -0.018588127568364143, 0.02049853652715683, 0.009837903082370758, -0.008338860236108303, -0.004831797908991575, -0.0029858837369829416, -0.015980491414666176, -0.009398648515343666, -0.007578880526125431, -0.011622809804975986, -0.015534264966845512, -0.009224341250956059, 0.010416602715849876, -0.022130051627755165, -0.016942666843533516, -0.010904663242399693, 0.016036270186305046, 0.0067422054708004, 0.008757198229432106, 0.2045949101448059, -0.013449549674987793, 0.002109118038788438, 0.047829918563365936, 0.003977692220360041, -0.002370578935369849, 0.025016581639647484, 0.00626111775636673, -0.001145198824815452, 0.012020230293273926, -0.015799211338162422, -0.007286044303327799, -0.012501318007707596, 0.0061495606787502766, 0.00027910954668186605, -0.029144177213311195, -0.02553253062069416, -0.039518944919109344, 0.006665510591119528, -0.01441869791597128, 0.003548896173015237, -0.007962356321513653, -0.01717972569167614, 0.003527979366481304, 0.024807412177324295, -0.005651041865348816, -0.005773057229816914, 0.014586033299565315, 0.011845923028886318, 0.01308699045330286, -0.00880600418895483, -0.004713268950581551, 0.015366929583251476, 0.009280120022594929, -0.020582202821969986, 0.004821339622139931, 0.008638668805360794, 0.0033362414687871933, 0.011302083730697632, 0.01680322177708149, -0.0037127451505512, 0.013045157305896282, -0.01407705619931221, -0.0264947060495615, 0.01584104634821415, 0.023454787209630013, -0.018560240045189857, 0.006627162918448448, -0.008861782029271126, 0.01974552869796753, -0.03826393559575081, -0.0027540549635887146, 0.0200801994651556, 0.031542643904685974, 0.015018315054476261, 0.010904663242399693, 0.034973014146089554, 0.0015966546488925815, -0.026578374207019806, 0.006107727065682411, -0.0074952132999897, 0.012131786905229092, -0.017570173367857933, 0.004838770255446434, -0.0033850474283099174, 0.01772356405854225, -0.0346941202878952, -0.003719717264175415, 0.02070770412683487, -0.011364834383130074, -0.009928543120622635, -0.04214052855968475, 0.003167163347825408, 0.004211263731122017, -0.016454607248306274, -0.03778981789946556, 0.03260243311524391, 0.03140319883823395, 0.02312011830508709, 0.006686427164822817, 0.005330316722393036, 0.004695838317275047, -0.014132834039628506, -0.008603807538747787, 0.021098153665661812, -0.041248075664043427, 0.02457035519182682, 0.015590042807161808, -0.005194357130676508, -0.005570860579609871, 0.010374769568443298, -0.020637981593608856, -0.008039051666855812, 0.00537912268191576, 0.01217362005263567, 0.018922798335552216, 0.0038138432428240776, 0.02157226949930191, -0.004577309358865023, -0.007390628568828106, -0.009482315741479397, -0.0170681681483984, 0.03815237805247307, 0.005407012067735195, 0.007251183036714792, -0.0067840395495295525, -0.006634135264903307, 0.010339908301830292, 0.002700019860640168, -0.02408229373395443, 0.005508109927177429, -0.016900833696126938, 0.0046853795647621155, 0.006571384612470865, 0.01803034543991089, 0.0071082510985434055, -0.0024246142711490393, -0.02076348289847374, 0.019522415474057198, 0.005619666539132595, -0.01600838080048561, -0.01137180719524622, 0.012494346126914024, 0.010953469201922417, -0.003911455161869526, -0.013365882448852062, -0.017361005768179893, 0.021474657580256462, -0.012717459350824356, -0.031012751162052155, 0.012689569965004921, -0.01968974992632866, 0.011929590255022049, 0.008819948881864548, 0.0004723727179225534, 0.010855857282876968, 0.012215454131364822, 0.0014842265518382192, -0.005452331621199846, 0.005563888233155012, -0.015408763661980629, -0.010939524509012699, 0.021377045661211014, 0.019355081021785736, 0.007286044303327799, -0.025086304172873497, 0.0021544380579143763, -0.017458617687225342, -0.0009029117063619196, -0.01878335326910019, -0.03483356535434723, -0.0067282612435519695, -0.015422708354890347, 0.012633792124688625, 0.0277218297123909, -0.007195404730737209, -0.037064701318740845, -0.007042014040052891, -0.0005804432439617813, 0.023942848667502403, -0.02953462488949299, 0.007251183036714792, 0.03971417248249054, -0.013268270529806614, -0.011936563067138195, -0.00950323324650526, -0.18284136056900024, 0.03547501936554909, 0.01964791677892208, -0.028168056160211563, 0.017849065363407135, 0.009754235856235027, 0.010186517611145973, -0.009851847775280476, -0.013045157305896282, 0.009949459694325924, 0.013602940365672112, -0.006986235734075308, -0.04453899711370468, -0.01129511184990406, 0.00920342467725277, -0.0016489468980580568, -4.45572986791376e-05, -0.015157761052250862, 0.019299302250146866, 0.007467323914170265, 0.009949459694325924, -0.0060449764132499695, -0.012166648171842098, -0.013351937755942345, 0.007299988996237516, -0.0030050575733184814, 0.007843827828764915, 0.007634658832103014, 0.004538961686193943, -0.011769227683544159, -0.019466636702418327, -0.022227665409445763, 0.022185830399394035, -0.0026825889945030212, 0.03474989905953407, 0.01578526757657528, -0.016817167401313782, 0.0018999493913725019, 0.014641812071204185, 0.03218409791588783, 0.00720934895798564, 0.0339411124587059, 0.004033470526337624, -0.0018284834222868085, 0.014837035909295082, 0.034973014146089554, -0.008931505493819714, 0.0021614101715385914, 0.019829196855425835, -0.005752140190452337, -0.0043088761158287525, -0.02136310003697872, 0.033048659563064575, -6.449369539041072e-05, 0.03023185394704342, 0.033104438334703445, 0.0013866143999621272, 0.021544380113482475, -3.7122004869161174e-05, -0.009796069003641605, 0.004141541197896004, -0.014091000892221928, 0.007146598305553198, -0.012187564745545387, 0.0014633096288889647, -0.007021097466349602, 0.0007991988677531481, -0.00573819549754262, -0.025699865072965622, -0.00013149305596016347, -0.011127776466310024, -0.02183721587061882, 0.01284296065568924, -0.0069444021210074425, 0.006909540854394436, -0.012333983555436134, -0.021000541746616364, 0.033048659563064575, 0.0046644629910588264, -0.014390809461474419, -0.029144177213311195, 0.020247533917427063, -0.012236370705068111, 0.000557783292606473, 0.014669700525701046, 0.0016358738066628575, -0.0013238637475296855, -0.0004950326983816922, -0.014376864768564701, -0.0021282918751239777, 0.027847331017255783, -0.026132147759199142, -0.022297387942671776, -0.01750045083463192, 0.02306433953344822, 0.0373435914516449, 0.0018406849121674895, 0.008171525783836842, -0.010932552628219128, -0.007627686485648155, -0.0027488258201628923, -0.016468551009893417, -0.027415048331022263, 0.024863190948963165, 0.03868227079510689, -0.003932372201234102, 0.0011338688200339675, -0.018420793116092682, 0.031654201447963715, 0.0024542466271668673, -0.022074274718761444, 0.008499222807586193, 0.0040090675465762615, 0.02600664645433426, 0.00200801994651556, 0.021711714565753937, 0.011560059152543545, -0.010528159327805042, 0.03173787146806717, -0.015018315054476261, 0.04849925637245178, 0.002185813384130597, -0.012431595474481583, 0.018072178587317467, 0.01872757449746132, -0.002272967016324401, -0.1103295385837555, -0.02232527732849121, 0.01407705619931221, 0.02119576558470726, -0.018867019563913345, 0.0049294098280370235, -0.011650698259472847, 0.003247344633564353, -0.007822910323739052, 0.018964631482958794, -0.02157226949930191, -0.034275785088539124, -0.007146598305553198, -7.805698260199279e-05, 0.0064284526742994785, -0.022562334313988686, -0.016287272796034813, -0.027958888560533524, -0.0067422054708004, 0.025504641234874725, -0.010667605325579643, 0.005616180598735809, 0.005978739820420742, -0.017639897763729095, 0.008025106973946095, 0.004514558706432581, 0.005386095028370619, 0.008799031376838684, 0.029255734756588936, -0.007237238343805075, 0.005434900987893343, -0.026020590215921402, 0.003566327039152384, -0.025881145149469376, -0.02161410264670849, -0.023482676595449448, -0.043116647750139236, -3.4126096579711884e-05, 0.01787695474922657, -0.02836327999830246, 0.03756670653820038, -0.008324915543198586, 0.0008318814798258245, -0.021753549575805664, -0.013268270529806614, 0.00883389264345169, -0.011357862502336502, 0.0162175502628088, 0.015129871666431427, -0.025197859853506088, -0.04222419485449791, -0.009733318351209164, -0.024542465806007385, -0.004392543341964483, 0.04389754682779312, -0.018588127568364143, 0.02515602670609951, 0.004043928813189268, 0.007087334059178829, -0.0036430221516638994, -0.007174487691372633, 0.009475343860685825, -0.022464722394943237, 0.012717459350824356, -0.017918787896633148, -0.006797983776777983, 0.001065017539076507, 0.0004571208555717021, 0.01584104634821415, -0.01772356405854225, 0.01750045083463192, 0.000518999935593456, -0.008143636398017406, 0.02981351688504219, -0.024068349972367287, 0.009621761739253998, -0.041554857045412064, -0.008303998969495296, 0.026132147759199142, -0.022394999861717224, -0.023148007690906525, -0.02510024793446064, 0.041248075664043427, -0.013867887668311596, 0.030008740723133087, 0.004563364665955305, 0.010172572918236256, -0.007195404730737209, 0.003283949103206396, -0.05095350369811058, -0.006745691876858473, 0.0023496621288359165, 0.03137531131505966, -0.031821537762880325, 0.0008288311073556542, 0.013714496977627277, -0.018016399815678596, -0.012320038862526417, 0.006456341594457626, -0.004946840461343527, -0.014837035909295082, -0.02242288924753666, -0.08193836361169815, 0.013798164203763008, 0.004322820343077183, -0.0006828487967140973, -0.0028446947690099478, 0.0021404933650046587, 0.0032386293169111013, 0.0034756872337311506, -0.023831291124224663, -0.005082800518721342, -0.013184602372348309, 0.0304549690335989, -0.0061844224110245705, 0.008917560800909996, -0.029032621532678604, -0.005853238515555859, 0.020205700770020485, 0.012501318007707596, 0.007460351567715406, 0.004322820343077183, 0.0007944054086692631, 0.004183374810963869, 0.041833747178316116, 0.012027202174067497, -0.011497308500111103, 0.005103717092424631, 0.004971243441104889, 0.004737671930342913, -0.010402658954262733, -0.006770094856619835, 0.00699669448658824, -0.030761748552322388, 0.0025745185557752848, 0.029395179823040962, -0.005853238515555859, -0.035196125507354736, -0.0050444528460502625, 0.02515602670609951, -0.013470466248691082, 0.004647031892091036, -0.009830930270254612, -0.02210216410458088, -0.002307828515768051, -0.01123933307826519, -0.017584118992090225, 0.020902929827570915, -0.0148509806022048, 0.025462808087468147, 0.007990245707333088, 0.0014118889812380075, 0.013414688408374786, 0.01378421951085329, 0.006020573433488607, 0.009496260434389114, -0.011727393604815006, -0.03313232958316803, 0.027094323188066483, 0.008638668805360794, -0.014174668118357658, -0.0059682815335690975, 0.01712394692003727, 0.024654021486639977, 0.005413983948528767, -0.006512119900435209, 0.01664983108639717, -0.029088398441672325, -0.018643906340003014, -0.007550991605967283, 4.9132864660350606e-05, -0.044064879417419434, -0.01717972569167614, -0.016496440395712852, -0.009907625615596771, -0.0020045337732881308, 0.0034512842539697886, 0.02040092460811138, 0.011685560457408428, -0.014244390651583672, -0.010374769568443298, 0.020428813993930817, 0.0166916660964489, -0.01294754445552826, -0.018978577107191086, 0.021488601341843605, 0.006829359102994204, 0.012640764005482197, -0.0012750577880069613, 0.003270004643127322, 0.002536170883104205, -0.002009762916713953, 0.0002281246561324224, 0.01985708624124527, 0.010451464913785458, -0.0005468890885822475, 0.011058053933084011, 0.015562154352664948, -0.0073487949557602406, -0.010702467523515224, 0.013637801632285118, 0.032992880791425705, -0.0024647049140185118, 0.006365702021867037, 0.004657490644603968, -0.00787171721458435, -0.007808966096490622, -0.003649994498118758, -0.016789278015494347, -0.003998609259724617, -0.0008358033956028521, 0.013282215222716331, 0.015046204440295696, 0.017472561448812485, -0.003848704742267728, 0.027958888560533524, -0.004580795299261808, 0.006710830144584179, -0.014669700525701046, -0.029478847980499268, -0.05678233876824379, 0.024319352582097054, 0.018155846744775772, -0.005033994093537331, 0.03296499326825142, 0.0002717014867812395, 0.01247342862188816, 0.019201690331101418, 0.015450597740709782, -0.010249268263578415, -0.017737509682774544, -0.0009281862876378, -0.0041450271382927895, -0.02070770412683487, -0.032239872962236404, -0.0008645640918985009, -0.008115747012197971, -0.007983273826539516, -0.007293016649782658, 0.02832144685089588, -0.0221579410135746, 0.045459337532520294, 0.01600838080048561, -0.02226949855685234, 0.02804255485534668, -0.014725479297339916, 0.02236711047589779, -0.002138750394806266, 0.011141721159219742, -0.01432108599692583, -0.0032734908163547516, 0.020484590902924538, -0.023566344752907753, 0.00966359581798315, -0.019954698160290718, -0.012905711308121681, 0.011065025813877583, -0.022938838228583336, 0.014586033299565315, -0.013414688408374786, -0.002320030005648732, 0.01262681931257248, 0.004416946321725845, 0.01298240665346384, -0.006090296432375908, 0.0013962013181298971, -0.028697950765490532, 0.013777247630059719, 0.009914598427712917, -0.010688522830605507, -0.01851840503513813, 0.019355081021785736, -0.005776543170213699, -0.02387312613427639, -0.009161590598523617, 0.02853061631321907, -0.009210396558046341, -0.00783685501664877, -0.011873812414705753, 0.009559011086821556, 0.004497128073126078, -0.01776539720594883, 0.013714496977627277, -0.02430540695786476, -0.043646544218063354, 0.010019182227551937, 0.0100400997325778, -0.0043053897097706795, -0.018713628873229027, -0.011253277771174908]\n"
     ]
    }
   ],
   "source": [
    "embedding_queen = response.data[0].embedding\n",
    "print(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f900a0-d8fd-47bd-b2ee-fe6bcd568a5a",
   "metadata": {
    "id": "a9f900a0-d8fd-47bd-b2ee-fe6bcd568a5a",
    "outputId": "e2c33401-a7d4-4a0a-ee35-751b6893e343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "print(len(response.data[0].embedding))\n",
    "print(response.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c662d-fda1-4da6-8ce7-c532e56b9325",
   "metadata": {
    "id": "905c662d-fda1-4da6-8ce7-c532e56b9325"
   },
   "source": [
    "Ici, l'embedding est un vecteur de taille 1536. À noter que le modèle qui est utilisé pour faire l'embedding n'est pas GPT-3. Le modèle d'embedding le plus lourd proposé par OpenAI, `text-embedding-3-large`, produit un embedding de dimension 3072.\n",
    "\n",
    "Maintenant, nous allons voir comment trouver le mot le plus proche d'un mot donné dans une liste de mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eadf31b-b08f-4a3d-bb86-91833f3395cf",
   "metadata": {
    "id": "9eadf31b-b08f-4a3d-bb86-91833f3395cf"
   },
   "outputs": [],
   "source": [
    "# On définit une liste de mot\n",
    "words = [\"woman\", \"man\", \"boat\", \"vector\", \"search\", \"data\",\n",
    "         \"science\", \"machine\", \"learning\", \"intelligence\"]\n",
    "\n",
    "# On génère des embeddings pour chaque mot :\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=words\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2fa37bb-e39d-43d3-b22a-d0e2027719ff",
   "metadata": {
    "id": "c2fa37bb-e39d-43d3-b22a-d0e2027719ff"
   },
   "outputs": [],
   "source": [
    "# On les stocke dans un dictionnaire\n",
    "word_embeddings = {\n",
    "    word: data.embedding\n",
    "    for word, data in zip(words, response.data)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f944da7-278a-43d8-8821-c1ea35b8b999",
   "metadata": {
    "id": "7f944da7-278a-43d8-8821-c1ea35b8b999"
   },
   "source": [
    "On définit ensuite la fonction de cosinus similarity pour comparer deux vecteurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c390d1e-dabb-4115-ba85-8589e8da1459",
   "metadata": {
    "id": "4c390d1e-dabb-4115-ba85-8589e8da1459"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NB : c'est bien de spécifier le type des paramètres d'une fonction\n",
    "def cosine_similarity(vec1: list, vec2: list):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "# NB il est également possible d'utiliser la fonction cosine_similarity\n",
    "# de la librairie sklearn.metrics.pairwise :\n",
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5734d6f-0441-4593-adac-c973890ec74d",
   "metadata": {
    "id": "a5734d6f-0441-4593-adac-c973890ec74d"
   },
   "source": [
    "Et on boucle sur nos embeddings pour trouver le mot le plus proche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec501ba4-e28f-4b8b-8040-84a5d69dd4c0",
   "metadata": {
    "id": "ec501ba4-e28f-4b8b-8040-84a5d69dd4c0",
    "outputId": "6c4b9f45-3cba-440a-d886-a2b9646fafbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word with the closest embedding is: woman\n"
     ]
    }
   ],
   "source": [
    "closest_word = None\n",
    "highest_similarity = -1  # Initialize with the lowest possible similarity\n",
    "\n",
    "for word, embedding in word_embeddings.items():\n",
    "    similarity = cosine_similarity(embedding_queen, embedding)\n",
    "    if similarity > highest_similarity:\n",
    "        highest_similarity = similarity\n",
    "        closest_word = word\n",
    "\n",
    "print(f\"The word with the closest embedding is: {closest_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29f0b3-78fd-42b9-ad6f-dcbda297ec96",
   "metadata": {
    "id": "0c29f0b3-78fd-42b9-ad6f-dcbda297ec96"
   },
   "source": [
    "**Exercice** : À vous de jouer ! Quel est le mot le plus proche de \"king - man + woman\" dans la liste suivante ? Quel est le deuxième mot le plus proche ? Attention, cette liste de mot est différente de la précédente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "020f2941-5e73-4da1-a1cf-522888084427",
   "metadata": {
    "id": "020f2941-5e73-4da1-a1cf-522888084427"
   },
   "outputs": [],
   "source": [
    "# Define the list of words to search within\n",
    "words = [\n",
    "    \"man\", \"boat\", \"vector\", \"search\", \"data\", \"science\",\n",
    "    \"machine\", \"learning\", \"intelligence\", \"queen\", \"princess\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "585404de-b0f3-4a5f-a17a-43c574633d87",
   "metadata": {
    "id": "585404de-b0f3-4a5f-a17a-43c574633d87"
   },
   "outputs": [],
   "source": [
    "# On génère les embeddings pour ces mots\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=words\n",
    ")\n",
    "# On les stocke dans un dictionnaire\n",
    "word_embeddings = {word: data.embedding for word, data in zip(words, response.data)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "816a95c4-b068-4a09-88c2-7640c008cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_of_words(words:list):\n",
    "    response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=words)\n",
    "    # On les stocke dans un dictionnaire\n",
    "    word_embeddings = {word: data.embedding for word, data in zip(words, response.data)}\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad9d1c1e-43ea-4ef8-a3de-ee34f2468307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding_of_word(word:str):\n",
    "    response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=word)\n",
    "    # On les stocke dans un dictionnaire\n",
    "    word_embedding = response.data[0].embedding\n",
    "    return word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815d87c-e901-488f-ac75-4267d40c0845",
   "metadata": {
    "id": "7815d87c-e901-488f-ac75-4267d40c0845"
   },
   "source": [
    "On récupère les embeddings pour chacun des mots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30bb2bb0-6d24-4d54-8d37-c0cda94230d2",
   "metadata": {
    "id": "30bb2bb0-6d24-4d54-8d37-c0cda94230d2"
   },
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=\"king\"\n",
    ")\n",
    "embedding_king = response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "321c649b-3cad-4d8e-a37d-b3843b1c5d29",
   "metadata": {
    "id": "321c649b-3cad-4d8e-a37d-b3843b1c5d29"
   },
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=\"man\"\n",
    ")\n",
    "embedding_man = response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eaeb498-8c91-45db-8f38-7771cfe51361",
   "metadata": {
    "id": "5eaeb498-8c91-45db-8f38-7771cfe51361"
   },
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    input=\"woman\"\n",
    ")\n",
    "embedding_woman = response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a61c6f1",
   "metadata": {
    "id": "3a61c6f1"
   },
   "source": [
    "On définit l'embedding qui nous intéresse :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c7ddb4-fd76-4c4c-be2c-572381105fdd",
   "metadata": {
    "id": "e6c7ddb4-fd76-4c4c-be2c-572381105fdd"
   },
   "outputs": [],
   "source": [
    "vecteur_diff = np.array(embedding_king) - np.array(embedding_man) + np.array(embedding_woman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ce1337e-af14-486f-bf96-9a3df5638e6a",
   "metadata": {
    "id": "4ce1337e-af14-486f-bf96-9a3df5638e6a",
    "outputId": "fc47bfef-4439-49b0-d654-d2902ae7218d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word with the closest embedding is: queen\n"
     ]
    }
   ],
   "source": [
    "closest_word = None\n",
    "highest_similarity = -1\n",
    "\n",
    "for word, embedding in word_embeddings.items():\n",
    "    similarity = cosine_similarity(vecteur_diff, embedding)\n",
    "    if similarity > highest_similarity:\n",
    "        highest_similarity = similarity\n",
    "        closest_word = word\n",
    "\n",
    "print(f\"The word with the closest embedding is: {closest_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44de2e7-348d-49da-8c46-efed742ce522",
   "metadata": {
    "id": "c44de2e7-348d-49da-8c46-efed742ce522"
   },
   "source": [
    "On peut adapter ce code pour trouver le deuxième mot le plus proche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3b293ee-da06-452c-8bf1-afc166b82a03",
   "metadata": {
    "id": "d3b293ee-da06-452c-8bf1-afc166b82a03"
   },
   "outputs": [],
   "source": [
    "closest_word = None\n",
    "l_similarity = []\n",
    "l_word = []\n",
    "\n",
    "for word, embedding in word_embeddings.items():\n",
    "    similarity = cosine_similarity(vecteur_diff, embedding)\n",
    "    l_word.append(word)\n",
    "    l_similarity.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d9da941-06f2-49d1-bdd0-65728b8ac049",
   "metadata": {
    "id": "1d9da941-06f2-49d1-bdd0-65728b8ac049",
    "outputId": "0078f3ba-903b-426a-b936-eca7ff7fc26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word with the closest embedding is: queen\n",
      "The word with the second closest embedding is: princess\n"
     ]
    }
   ],
   "source": [
    "l_idx_ordered = np.argsort(l_similarity)\n",
    "word_closest = l_word[l_idx_ordered[-1]]\n",
    "word_second_closest = l_word[l_idx_ordered[-2]]\n",
    "\n",
    "print(f\"The word with the closest embedding is: {word_closest}\")\n",
    "print(f\"The word with the second closest embedding is: {word_second_closest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32b07278-f170-42e6-81f9-d40e324fafbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_em = get_embedding_of_word(\"earth\")\n",
    "m_em = get_embedding_of_word(\"moon\")\n",
    "s_em = get_embedding_of_word(\"sun\")\n",
    "\n",
    "vecteur_diff = np.array(s_em) - np.array(e_em) + np.array(m_em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefab978-0a7e-4e32-8cb0-680d6483558e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67d0c16c-2ada-4ae1-8619-f60c650023a4",
   "metadata": {
    "id": "67d0c16c-2ada-4ae1-8619-f60c650023a4"
   },
   "source": [
    "**Quelques propriétés des embeddings** :\n",
    "\n",
    "Illustrons la toute puissance de l'embedding d'OpenAI en réduisant de force la dimension des embeddings, et en constatant que ça fonctionne toujours !\n",
    "\n",
    "Voir la très bonne documentation d'OpenAI sur le sujet :\n",
    "- https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "- https://platform.openai.com/docs/guides/embeddings/use-cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf8fced2-8599-4a76-960c-b08f494e13cc",
   "metadata": {
    "id": "bf8fced2-8599-4a76-960c-b08f494e13cc",
    "outputId": "a77367d6-bab0-4661-943e-c4173f108dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word with the closest embedding is: queen\n",
      "The word with the second closest embedding is: princess\n"
     ]
    }
   ],
   "source": [
    "closest_word = None\n",
    "l_similarity = []\n",
    "l_word = []\n",
    "\n",
    "for word, embedding in word_embeddings.items():\n",
    "    vecteur_diff = np.array(vecteur_diff)[:500]\n",
    "    embedding = np.array(embedding)[:500]\n",
    "    similarity = cosine_similarity(vecteur_diff, embedding)\n",
    "    l_word.append(word)\n",
    "    l_similarity.append(similarity)\n",
    "\n",
    "l_idx_ordered = np.argsort(l_similarity)\n",
    "word_closest = l_word[l_idx_ordered[-1]]\n",
    "word_second_closest = l_word[l_idx_ordered[-2]]\n",
    "\n",
    "print(f\"The word with the closest embedding is: {word_closest}\")\n",
    "print(f\"The word with the second closest embedding is: {word_second_closest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k4TQpg7jt0D1",
   "metadata": {
    "id": "k4TQpg7jt0D1"
   },
   "source": [
    "# 2) OpenAI pour text generation et Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c404f7-18c4-427e-8257-e3746eb3d465",
   "metadata": {
    "id": "16c404f7-18c4-427e-8257-e3746eb3d465"
   },
   "source": [
    "## Tokéniser du texte\n",
    "\n",
    "On commence par tokéniser du texte. En fonction du modèle que l'on va utiliser, il faut choisir la bonne méthode de tokénisation (un détail parfois caché dans le code, surtout lorsque l'on fait des calls API). Ici, on va utiliser le tokenizer `cl100k_base`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87140724-5be7-45d2-a54d-c0a3fd0f1754",
   "metadata": {
    "id": "87140724-5be7-45d2-a54d-c0a3fd0f1754",
    "outputId": "0b5c43a5-abc1-4544-98f0-83509c3b7390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1687, 690, 3974, 304, 12366, 719, 37990, 16373, 1618]\n"
     ]
    }
   ],
   "source": [
    "example_string = 'We will live in Paris but ewhd here'\n",
    "# Définir la méthode pour encoder (tokenizer préentraîné)\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "# On tokénise\n",
    "token_integers = encoding.encode(example_string)\n",
    "# Puis on renvoie les indices des différents tokens obtenus\n",
    "# dans le dictionnaire des tokens associé au tokenizer.\n",
    "print(token_integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab69850",
   "metadata": {
    "id": "7ab69850"
   },
   "source": [
    "On peut de même faire la transformation inverse : reconstruire la phrase à partir des tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f830aa48-727b-46bc-b6af-1faefd3850e8",
   "metadata": {
    "id": "f830aa48-727b-46bc-b6af-1faefd3850e8",
    "outputId": "42e5ea70-29c3-4c77-d4d2-088dfcb75541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'We', b' will', b' live', b' in', b' Paris', b' but', b' ew', b'hd', b' here']\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(token_integers)\n",
    "token_bytes = [encoding.decode_single_token_bytes(token) for token in token_integers]\n",
    "print(token_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9307a94-ded5-4c0b-956d-f22abe2f98ab",
   "metadata": {
    "id": "e9307a94-ded5-4c0b-956d-f22abe2f98ab"
   },
   "source": [
    "On peut comparer les tokens en fonction du type d'encoding considéré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "922d3714-5102-4651-97c7-b93cd19f1c30",
   "metadata": {
    "id": "922d3714-5102-4651-97c7-b93cd19f1c30",
    "outputId": "bace418f-ef74-4a44-99bd-d491e7fcacb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r50k_base: 10 tokens\n",
      "token integers: [1135, 481, 2107, 287, 6342, 475, 304, 1929, 67, 994]\n",
      "token bytes: [b'We', b' will', b' live', b' in', b' Paris', b' but', b' e', b'wh', b'd', b' here']\n",
      "p50k_base: 10 tokens\n",
      "token integers: [1135, 481, 2107, 287, 6342, 475, 304, 1929, 67, 994]\n",
      "token bytes: [b'We', b' will', b' live', b' in', b' Paris', b' but', b' e', b'wh', b'd', b' here']\n",
      "cl100k_base: 9 tokens\n",
      "token integers: [1687, 690, 3974, 304, 12366, 719, 37990, 16373, 1618]\n",
      "token bytes: [b'We', b' will', b' live', b' in', b' Paris', b' but', b' ew', b'hd', b' here']\n"
     ]
    }
   ],
   "source": [
    "for encoding_name in [\"r50k_base\", \"p50k_base\", \"cl100k_base\"]:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    token_integers = encoding.encode(example_string)\n",
    "    num_tokens = len(token_integers)\n",
    "    token_bytes = [encoding.decode_single_token_bytes(token) for token in token_integers]\n",
    "\n",
    "    print(f\"{encoding_name}: {num_tokens} tokens\")\n",
    "    print(f\"token integers: {token_integers}\")\n",
    "    print(f\"token bytes: {token_bytes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9bda95-0d6e-4110-be68-d98b6ff6be6f",
   "metadata": {
    "id": "bb9bda95-0d6e-4110-be68-d98b6ff6be6f"
   },
   "source": [
    "On peut aussi utiliser le tokenizer de la librairie `transformers` de HuggingFace, qui centralise de nombreux types de tokenizers différents en fonction du modèle utilisé. Voir la [documentation](https://huggingface.co/docs/transformers/v4.41.3/en/model_doc/auto#transformers.AutoTokenizer) pour la liste des modèles supportés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d76bcf5-4d3e-4083-b31a-fad48b053ae7",
   "metadata": {
    "id": "4d76bcf5-4d3e-4083-b31a-fad48b053ae7",
    "outputId": "86d9e28d-4da3-473e-97f2-4b78e0589a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1109867-20c1-47dd-990d-4377e66e3a24",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c436fec735b046f2aa64af77bae5bd83",
      "96a98809a331486da1f6793987a7c0e2",
      "5b03e0694b41439b91d9c8e5ad287256",
      "69f98aad39c944c186d680469c465650"
     ]
    },
    "id": "c1109867-20c1-47dd-990d-4377e66e3a24",
    "outputId": "1af818af-a49f-4432-9b8a-72a340022507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: [\"'\", 'we', 'live', 'in', 'paris', 'but', 'e', '##w', '##hd', 'here', \"'\"]\n",
      "Token IDs: [1005, 2057, 2444, 1999, 3000, 2021, 1041, 2860, 14945, 2182, 1005]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Charger un tokenizer pré-entraîné\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# https://huggingface.co/docs/transformers/v4.41.3/en/model_doc/auto#transformers.AutoTokenizer\n",
    "\n",
    "# Chaîne de caractères\n",
    "text = \"'We live in Paris but ewhd here'\"\n",
    "\n",
    "# Tokénisation\n",
    "tokens = tokenizer.tokenize(text)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Token IDs:\", token_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e8e0a-38da-4843-8dcb-4301e4c4fe9f",
   "metadata": {
    "id": "9b9e8e0a-38da-4843-8dcb-4301e4c4fe9f"
   },
   "source": [
    "## Faire de la génération de texte\n",
    "\n",
    "Dire que l'on pourrait faire differents endpoints ? Mais que pour de la generation de texte pure, on prefere autre chose.\n",
    "\n",
    "'completions', 'chat', 'embeddings', 'files', 'images', 'audio', 'moderations', 'models', 'fine_tuning', 'beta', 'batches', 'with_raw_response', 'with_streaming_response'\n",
    "\n",
    "https://platform.openai.com/docs/guides/text-generation\n",
    "Pour les APIs, les details sont abstrait par contre il faut absolument lire la documentation.\n",
    "Voir plutot directement l'API de OpenAI pour cela ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0a08ef1-e854-4060-b2bd-d38f70382740",
   "metadata": {
    "id": "a0a08ef1-e854-4060-b2bd-d38f70382740"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from LLMPlayplace.credentials.keys import OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "prompt = 'Tell me a story about nights and frogs'\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "997cf130-acc0-44fe-8607-6b7ebdde3e38",
   "metadata": {
    "id": "997cf130-acc0-44fe-8607-6b7ebdde3e38",
    "outputId": "e0376b6c-d980-4ccb-e502-19cdd5247928"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once there was a small village nestled in the countryside, surrounded by lush green\n"
     ]
    }
   ],
   "source": [
    "# Extract and print the generated text\n",
    "generated_text = response.choices[0].text.strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaeb6b5-d03d-4154-b2b0-b62c87ead711",
   "metadata": {
    "id": "9eaeb6b5-d03d-4154-b2b0-b62c87ead711"
   },
   "source": [
    "La longueur par défaut du texte généré n'est pas suffisamment longue, il faut donc explicitement demander à ce qu'elle soit plus longue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9978915d-cce1-43b7-a163-8a330b46733f",
   "metadata": {
    "id": "9978915d-cce1-43b7-a163-8a330b46733f",
    "outputId": "c31fdf42-5177-4cd8-fef3-b20c475941fa",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a small village nestled in the heart of a dense forest. The villagers were a close-knit community, living simple lives and relying on each other for support. However, their nights were never peaceful. As soon as the sun set and darkness crept in, a symphony of croaks and ribbits filled the air. The villagers weren't bothered by the sound, as they were used to it – it was the sound of the frogs that lived in the nearby pond.\n",
      "\n",
      "The villagers had grown so accustomed to the croaking that they couldn't imagine their nights being any other way. They even started to believe that the frogs brought good luck to the village. Legend had it that the first settlers of the village had made a deal with the frogs – in exchange for providing them a home, the frogs would protect the villagers from any harm.\n",
      "\n",
      "One night, a traveling storyteller visited the village and entertained the villagers with his tales. As he finished his last story, a young boy named Timmy asked him if he had any stories about frogs. The storyteller smiled and began his tale.\n",
      "\n",
      "He told the story of a young prince who was cursed by an evil sorcerer to turn into a frog every night. The prince was desperate to break the curse and sought help from a wise old frog who lived in the pond. The wise frog told him that the only way to break the curse was to find true love and receive a kiss from a princess.\n",
      "\n",
      "The prince embarked on a journey,\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Tell me a story about nights and frogs.'\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=300,  # Increase max_tokens to generate a longer text\n",
    ")\n",
    "\n",
    "generated_text = response.choices[0].text.strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6396c-9d3b-48ae-9be9-6da07ead39c4",
   "metadata": {
    "id": "b3e6396c-9d3b-48ae-9be9-6da07ead39c4"
   },
   "source": [
    "On peut aussi essayer le modèle plus récent `gpt-4o-mini`, mais la syntaxe est légèrement différente :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9969aef2-3dc8-483f-9379-ab09c33eb63b",
   "metadata": {
    "id": "9969aef2-3dc8-483f-9379-ab09c33eb63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a quiet village nestled between emerald hills and a shimmering lake, there was a peculiar legend about a night when frogs could sing. The villagers often shared whispered tales of the mystical Frogsong Night, which occurred on the first full moon of spring. They claimed that if you listened closely, you could hear the frogs crooning melodies that resonated with the very heart of nature.\n",
      "\n",
      "One such night arrived, casting a silver glow over the landscape. The stars twinkled like diamonds, and the moon hung low, draping everything in a soft, ethereal light. Young Clara, a spirited girl with a curious heart and a love for adventure, had heard the stories countless times but had never experienced the magic for herself. Determined to witness the legendary Frogsong Night, she set out towards the lake with a small lantern flickering at her side.\n",
      "\n",
      "As Clara approached the water's edge, she was struck by the beauty of the night. Fireflies danced around her, illuminating the path, and the gentle lull of the water created a soothing backdrop. She sat down on a mossy stone, her heart racing with excitement, and listened intently.\n",
      "\n",
      "At first, there was only the rustle of leaves and the occasional splash of a fish. But just as Clara began to doubt the tales, a soft croak echoed from the reeds. Then another, and soon the night air was filled with a gentle symphony of croaks, chirps, and whistles.\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}  # Chat-based message format\n",
    "    ],\n",
    "    max_tokens=300  # Control response length\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf60e1-6ed9-4225-90c3-14778090c929",
   "metadata": {
    "id": "5cbf60e1-6ed9-4225-90c3-14778090c929"
   },
   "source": [
    "Si on veut que l'histoire produite ne s'arrête pas brusquement, il faut le spécifier dans le prompt lui-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2485aeac-53a3-4edd-acf9-f844683a9b10",
   "metadata": {
    "id": "2485aeac-53a3-4edd-acf9-f844683a9b10",
    "outputId": "c0d9d3a3-4257-435a-9838-b470034f6917"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a tranquil village nestled by a shimmering lake, the nights came alive with the chorus of frogs. Each evening, as the sun dipped below the horizon, hundreds of green frogs gathered at the water’s edge, their voices weaving a melodic tapestry that filled the air. The villagers, enchanted by the symphony, often sat outside, sharing stories under the blanket of stars, while the frogs serenaded them with their rhythmic croaks.\n",
      "\n",
      "One fateful night, a curious little girl named Lila ventured closer to the pond, captivated by the moonlight dancing on the water. She noticed a lone frog sitting apart from the others, its skin shimmering like silver. Intrigued, she whispered, “Why do you sit alone?” The frog, surprisingly, replied in a soft voice, “I am the Night Prince, cursed to watch the merriment from afar until someone believes in magic.”\n",
      "\n",
      "Determined to help, Lila gathered the villagers, sharing the tale of the magical frog. Together, they sang and danced by the water, believing wholeheartedly in the wonder of the night. As the final note echoed through the air, the silver frog transformed into a dashing prince, grateful for their faith and kindness. From that night on, the frogs remained, not only as music-makers but as the guardians of dreams, ensuring the village always thrived in magic and joy.\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Tell me a story about nights and frogs. The story should be 10 sentences long at most.'\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}  # Chat-based message format\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d6f64a2-5ffe-43bb-86f2-7b604fd5b0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CompletionUsage(completion_tokens=278, prompt_tokens=27, total_tokens=305, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))\n"
     ]
    }
   ],
   "source": [
    "# to know how much we have used in the api\n",
    "# prompt_tokens=27 (input token), completion_tokens=278(output token)\n",
    "num=completion.usage\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3111280-e138-42c0-88dd-90f6917321e3",
   "metadata": {
    "id": "b3111280-e138-42c0-88dd-90f6917321e3"
   },
   "source": [
    "On pourrait tout à fait générer un très long texte en faisant à nouveau une génération à partir du dernier paragraphe obtenu.\n",
    "\n",
    "Il y a aussi de nombreux autres paramètres pour jouer sur la génération du texte :\n",
    "\n",
    "- **`temperature`**: Contrôle la créativité du résultat, de 0 a 1 avec 1 pour le plus créatif ;\n",
    "\n",
    "- **`top_p`**: Une valeur comprise entre 0 et 1 qui limite le modèle à ne considérer que les tokens avec la probabilité cumulée la plus élevée jusqu'à `top_p`.\n",
    "\n",
    "- **`top_k`**: choisir que parmi les k tokens les plus probables.\n",
    "\n",
    "- **`frequency_penalty`**: Une valeur entre -2.0 et 2.0. Les valeurs positives pénalisent les nouveaux tokens en fonction de leur fréquence existante dans le texte jusqu'à présent, réduisant ainsi la probabilité de répéter textuellement la même ligne.\n",
    "\n",
    "- **`presence_penalty`**: Une valeur comprise entre -2.0 et 2.0. Les valeurs positives pénalisent les nouveaux tokens selon qu'ils apparaissent ou non dans le texte jusqu'à présent, augmentant ainsi la probabilité d'introduire de nouveaux sujets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65282cf1-b780-4870-aeba-d8ed665e47d5",
   "metadata": {
    "id": "65282cf1-b780-4870-aeba-d8ed665e47d5",
    "outputId": "1615e9f3-4998-4385-ff09-6743dbc27a38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once there was a quiet village nestled deep in the heart of the forest. Every night, as the sun set and the moon rose high in the sky, the villagers would gather around the fire and share stories of their day. The nights were always so peaceful and calm, the only sounds being the rustle of leaves and the occasional hoot of an owl.\n",
      "\n",
      "But one night, as the villagers were settling in for their usual storytelling, they noticed something different. A loud croaking noise filled the\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Tell me a story about nights and frogs'\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt,\n",
    "    temperature=1,\n",
    "    max_tokens=100,  # Increase max_tokens to generate a longer text\n",
    ")\n",
    "\n",
    "generated_text = response.choices[0].text.strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2558f165-6572-4cad-9349-71f088510cf4",
   "metadata": {
    "id": "2558f165-6572-4cad-9349-71f088510cf4"
   },
   "source": [
    "Exemple avec le paramètre **`top_p`**, noter que le paramètre **`top_k`** n'est pas disponible via l'API OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c4108fd-b761-40ab-99ad-3cbf1678a956",
   "metadata": {
    "id": "0c4108fd-b761-40ab-99ad-3cbf1678a956",
    "outputId": "e32a2870-1f66-4ecf-b5f5-a04f752ed0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, in a peaceful village nestled in the heart of a dense forest, there lived a young girl named Lily. She was known for her love of nature and her fascination with the creatures of the forest. But there was one creature in particular that she was always drawn to - the frogs.\n",
      "\n",
      "Lily loved to spend her evenings wandering through the forest, listening to the soothing sound of the frogs croaking. She would often sit by the pond and watch them hop around, catching fireflies and chasing each other. It was her favorite pastime and she never grew tired of it.\n",
      "\n",
      "One night, as she was walking through the forest, Lily heard a strange noise coming from the direction of the pond. It sounded like a mix of croaking and singing. Curiosity getting the best of her, she followed the sound until she came upon a clearing in the forest. To her amazement, she saw a group of frogs gathered around a small campfire.\n",
      "\n",
      "Lily couldn't believe her eyes. She had never seen frogs gather like this before. As she approached, the frogs\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Tell me a story about nights and frogs'\n",
    "\n",
    "response = client.completions.create(\n",
    "    model=\"gpt-3.5-turbo-instruct\",\n",
    "    prompt=prompt,\n",
    "    top_p=0.8,\n",
    "    stop='stop',\n",
    "    temperature=2,\n",
    "    max_tokens=300,  # Increase max_tokens to generate a longer text\n",
    ")\n",
    "\n",
    "generated_text = response.choices[0].text.strip()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a806b88-ce6f-49fd-99ff-920d0e8e508e",
   "metadata": {
    "id": "9a806b88-ce6f-49fd-99ff-920d0e8e508e"
   },
   "source": [
    "## Faire du Q&A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b336e-9dcc-4095-b53f-8e840c9ce3e6",
   "metadata": {
    "id": "cd2b336e-9dcc-4095-b53f-8e840c9ce3e6"
   },
   "source": [
    "Pour plutôt utiliser le modèle en version \"chat\", nous allons utiliser le endpoint **`client.chat.completions`** au lieu de **`client.completions`**. Nous pouvons également l'utiliser pour de la génération de texte. Le format est légèrement différent, et il faut de nouveau se ramener à la documentation de l'API.\n",
    "\n",
    "Un [blog](https://platform.openai.com/docs/guides/text-generation/parameter-details) qui explique dans les grandes lignes le `client.chat.completion`, et la [documentation](https://platform.openai.com/docs/api-reference/chat) plus précise de l'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0577f1e3-49f4-43f4-89c8-f8ef26088a18",
   "metadata": {
    "id": "0577f1e3-49f4-43f4-89c8-f8ef26088a18"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from credentials.keys import OPENAI_API_KEY\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Make the API call for completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "      {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1eba85-1c71-4656-ba0f-76f361bcacdb",
   "metadata": {
    "id": "7d1eba85-1c71-4656-ba0f-76f361bcacdb",
    "outputId": "a16e23e6-9aab-4ff0-dd7f-1c355af8cf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of code where logic thrives,  \n",
      "A tale of recursion takes joyful dives.  \n",
      "A function within, calling its own name,  \n",
      "In a spiral of depth, it plays a grand game.  \n",
      "\n",
      "Picture a mirror, reflecting a sight,  \n",
      "A dancer in sequences, twirling in flight.  \n",
      "Each step a return to the very first beat,  \n",
      "A loop through dimensions, both tangled and neat.  \n",
      "\n",
      "\"Divide and conquer!\" the wise coder cries,  \n",
      "As data is broken, it multiplies.  \n",
      "With base cases waiting, a solid embrace,  \n",
      "To stop the recursion, give it a face.  \n",
      "\n",
      "\"To solve this great puzzle,\" the function will say,  \n",
      "\"I'll solve smaller pieces, and find my own way.  \n",
      "With each little call, I inch toward the light,  \n",
      "And gather the answers, all shining and bright.\"  \n",
      "\n",
      "Like nesting dolls, in a beautiful shell,  \n",
      "Each call unveils secrets, a magic to tell.  \n",
      "But beware of the depth, for the stack may soon weep,  \n",
      "If too far you journey, the limits will creep.  \n",
      "\n",
      "So cherish the cycle, a dance of pure grace,  \n",
      "In the heart of your function, recursion finds place.  \n",
      "For in layers it weaves, a tapestry spun,  \n",
      "A powerful tool, where two can become one.\n"
     ]
    }
   ],
   "source": [
    "# Et voici comment afficher le texte\n",
    "print(completion.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204cbbb5-3593-405d-a56f-8177385eb39d",
   "metadata": {
    "id": "204cbbb5-3593-405d-a56f-8177385eb39d"
   },
   "source": [
    "Ici, on fournit l'objet **`messages`** au lieu de **`prompt`**. Et **`messages`** doit etre une liste de messages ou chacun est un dictionnaire avec deux clefs:\n",
    "\n",
    "- `content` : le prompt.\n",
    "- `role` : ce champ indique le rôle de l'entité qui envoie le message, il faut choisir entre **`system`**, **`user`** et **`assistant`**:\n",
    "\n",
    "    - **`user`**: correspond à l'humain interagissant avec le modèle ;\n",
    "\n",
    "    - **`assistant`**: le LLM lui-même (pour spécifier la réponse qu'il est censé donner) ;\n",
    "\n",
    "    - **`system`**: des instructions/un contexte pour guider le comportement de l'assistant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "607642fe-4482-4ff0-baa0-687e808fa553",
   "metadata": {
    "id": "607642fe-4482-4ff0-baa0-687e808fa553",
    "outputId": "80471fce-5192-4755-8eca-d771734a3cf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Large Language Models (LLMs) are a type of artificial intelligence that uses deep learning techniques to understand, generate, and manipulate human language. Here are the main concepts behind LLMs:\n",
      "\n",
      "1. **Architecture**: Most LLMs are based on the Transformer architecture, which was introduced in the paper \"Attention is All You Need\" in 2017. This architecture utilizes mechanisms called \"self-attention\" and \"feed-forward neural networks\" to process sequences of text efficiently. The self-attention mechanism allows the model to weigh the importance of different words in a sentence relative to each other, enabling it to capture contextual relationships.\n",
      "\n",
      "2. **Training on Large Datasets**: LLMs are trained on vast amounts of text data from diverse sources such as books, articles, websites, and other written material. The training is typically unsupervised, meaning the model learns patterns in the data without needing labeled examples. During this phase, the model learns grammar, facts about the world, reasoning abilities, and some level of common sense.\n",
      "\n",
      "3. **Tokenization**: Text is broken down into smaller units called tokens, which can be words or subwords (like prefixes or suffixes). This process allows the model to handle a wide range of vocabulary and understand the nuances of different languages.\n",
      "\n",
      "4. **Pre-training and Fine-tuning**: The training process generally involves two phases:\n",
      "   - **Pre-training**: The model learns to predict the next word in a sentence given the preceding words (language modeling) or fills in missing words (masked language modeling). This phase helps the model learn general language patterns.\n",
      "   - **Fine-tuning**: After pre-training, the model can be further refined on specific tasks or datasets, such as sentiment analysis, question answering, or summarization, using supervised learning techniques where it learns from examples with labeled data.\n",
      "\n",
      "5. **Inference**: Once trained, LLMs can generate coherent and contextually relevant text based on a given input prompt. They can answer questions, carry on conversations, write essays, and perform various language tasks by predicting one token at a time until a complete response is formed.\n",
      "\n",
      "6. **Scalability and Performance**: LLMs are generally scaled up by increasing the number of parameters (neurons) in the model and the amount of training data. Larger models have been shown to perform better across various tasks, leading to more sophisticated understandings and text generation abilities.\n",
      "\n",
      "7. **Ethical and Social Considerations**: As LLMs are deployed in real-world applications, there are important discussions surrounding their ethical use, potential biases in the training data, and the implications of generating misleading or harmful content.\n",
      "\n",
      "In summary, LLMs leverage advanced neural network architectures, large-scale training, and sophisticated tokenization techniques to process and generate human language, making them powerful tools for a variety of natural language processing tasks.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Make the API call for completion\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert in Machine Learning and AI.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you explain the main concept behind LLMs ?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b41f5-84f8-49b2-9c0a-f22c3d9eaa20",
   "metadata": {
    "id": "778b41f5-84f8-49b2-9c0a-f22c3d9eaa20"
   },
   "source": [
    "Nous pouvons ainsi inclure de nombreux messages, et utiliser ce format pour de nombreux objectifs différents. Par exemple, nous pouvons donner des exemples du comportement du modèle que nous attendons. C'est une forme de **few-shot learning** qu'on appelle **few-shot prompting** et que nous allons expérimenter au prochain TP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1dcc96bb-db7e-4b6d-a42b-98d5dc547060",
   "metadata": {
    "id": "1dcc96bb-db7e-4b6d-a42b-98d5dc547060",
    "outputId": "1b7a7a10-e936-4992-c21c-34ae16c01d26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence is positive. It conveys a sense of optimism and a desire to enjoy the outdoors.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a very sensitive assitant.\"},\n",
    "        {\"role\": \"system\", \"content\": \"Consider the following sentence: the night is dark, and the rain is falling on my roof like a cloud of arrows.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Is this sentence positive or negative ?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"negative\"},\n",
    "        {\"role\": \"system\", \"content\": \"Today the sun is rising and I want to go outside.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Is this sentence positive or negative ?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058485d-b228-4069-aeb9-a7c35c374747",
   "metadata": {
    "id": "b058485d-b228-4069-aeb9-a7c35c374747"
   },
   "source": [
    "On peut ensuite packager nos prompts pour des applications systématiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5826aba3-15fa-4dc1-92ca-f14cd0816f68",
   "metadata": {
    "id": "5826aba3-15fa-4dc1-92ca-f14cd0816f68"
   },
   "outputs": [],
   "source": [
    "DEFAULT_TEMPERATURE = 0\n",
    "DEFAULT_MAX_TOKENS = 500\n",
    "DEFAULT_MODEL = \"gpt-4o-mini\" # ou \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8bab7c8f-706c-4e4e-9064-0fb54bd6122d",
   "metadata": {
    "id": "8bab7c8f-706c-4e4e-9064-0fb54bd6122d"
   },
   "outputs": [],
   "source": [
    "def send_prompt(prompt: str, model: str = DEFAULT_MODEL) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    # resp = openai.ChatCompletion.create(\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=DEFAULT_TEMPERATURE,\n",
    "        max_tokens=DEFAULT_MAX_TOKENS\n",
    "    )\n",
    "    answer = resp.choices[0].message.content.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3137f18d-541b-439b-9777-5c05d875aa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = send_prompt(\"write me a song\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7910dd97-18ed-4c67-9494-6bbe69128cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here’s an original song for you:\n",
      "\n",
      "**Title: \"Chasing Stars\"**\n",
      "\n",
      "**Verse 1:**  \n",
      "In the quiet of the night, when the world feels still,  \n",
      "I hear the whispers of dreams, they give me a thrill.  \n",
      "With every heartbeat, I’m ready to fly,  \n",
      "Leaving behind all the doubts, reaching for the sky.\n",
      "\n",
      "**Chorus:**  \n",
      "We’re chasing stars, lighting up the dark,  \n",
      "With every step we take, we’re igniting a spark.  \n",
      "Together we’ll rise, like the moon and the tide,  \n",
      "In this dance of life, let’s take it in stride.  \n",
      "\n",
      "**Verse 2:**  \n",
      "Through the storms and the shadows, we’ll find our way,  \n",
      "With the strength of our love, we’ll never sway.  \n",
      "Hand in hand, we’ll face what’s unknown,  \n",
      "In this journey together, we’re never alone.\n",
      "\n",
      "**Chorus:**  \n",
      "We’re chasing stars, lighting up the dark,  \n",
      "With every step we take, we’re igniting a spark.  \n",
      "Together we’ll rise, like the moon and the tide,  \n",
      "In this dance of life, let’s take it in stride.  \n",
      "\n",
      "**Bridge:**  \n",
      "So let the night unfold, let the magic begin,  \n",
      "With every wish we make, we’ll let the light in.  \n",
      "No matter the distance, no matter how far,  \n",
      "We’ll keep on believing, we’re chasing our stars.\n",
      "\n",
      "**Chorus:**  \n",
      "We’re chasing stars, lighting up the dark,  \n",
      "With every step we take, we’re igniting a spark.  \n",
      "Together we’ll rise, like the moon and the tide,  \n",
      "In this dance of life, let’s take it in stride.  \n",
      "\n",
      "**Outro:**  \n",
      "So here’s to the moments, the laughter, the tears,  \n",
      "With you by my side, I’ll conquer my fears.  \n",
      "We’re chasing stars, forever we’ll be,  \n",
      "In this beautiful journey, just you and me.\n",
      "\n",
      "Feel free to modify any part of it to make it your own!\n"
     ]
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a607406-1705-4dbc-a733-56243be2e92f",
   "metadata": {
    "id": "6a607406-1705-4dbc-a733-56243be2e92f"
   },
   "source": [
    "## TP : écrire des messages de bienvenue pour des clients d'hôtels\n",
    "\n",
    "Nous voulons avoir une méthode automatique pour écrire des messages de bienvenue à des gens visitant notre hôtel pour la première fois. Nous avons plusieurs contraintes:\n",
    "\n",
    "- Le message de bienvenue ne peut pas dépasser plus de 300 tokens.\n",
    "- Le message ne doit pas faire plus que 4 phrases.\n",
    "- Les messages doivent tous être très différents les uns des autres.\n",
    "- Le message doit être différent selon s'il s'agit d'une famille ou d'un couple.\n",
    "\n",
    "Écrire une fonction qui génère de tels messages avec ces contraintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7e2cee8d-8164-457c-be03-d6baa4e4d52d",
   "metadata": {
    "id": "7e2cee8d-8164-457c-be03-d6baa4e4d52d"
   },
   "outputs": [],
   "source": [
    "custom_temp = 0.3\n",
    "custom_p = 0.8\n",
    "\n",
    "def send_prompt_high_temp(prompt: str, model: str = DEFAULT_MODEL) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"The generated message must be less than 4 sentences\"},\n",
    "        {\"role\": \"system\", \"content\": \"You are the hotel owner.\"},\n",
    "        {\"role\": \"system\", \"content\": \"If the client is from china, the welcom message must be in chinese language.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The generated message must be different for family and couple\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    # resp = openai.ChatCompletion.create(\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        top_p=custom_p,\n",
    "        messages=messages,\n",
    "        temperature=custom_temp,\n",
    "        max_tokens=300\n",
    "    )\n",
    "    answer = resp.choices[0].message.content.strip()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8092e081-e367-4dc0-9e54-76f627a40e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Welcome to [Hotel Name]!**\n",
      "\n",
      "Dear [Couple's Names],\n",
      "\n",
      "Congratulations on your recent marriage! We are thrilled to have you as our guests and to be a part of this special chapter in your lives. \n",
      "\n",
      "As you embark on this beautiful journey together, we invite you to relax and indulge in the luxurious amenities and services we offer. Whether you’re looking to unwind by the pool, enjoy a romantic dinner at our restaurant, or explore the local attractions, our team is here to ensure your stay is unforgettable.\n",
      "\n",
      "Please don’t hesitate to reach out if there’s anything we can do to make your honeymoon even more special. We wish you a wonderful stay filled with love, laughter, and cherished memories.\n",
      "\n",
      "Warmest wishes,\n",
      "\n",
      "The [Hotel Name] Team\n"
     ]
    }
   ],
   "source": [
    "test1 = send_prompt(\"write me a welcome message for clients of the hotel. The clients are a young couple who just marrid\")\n",
    "print(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7307af4f-729a-4691-9488-5177fd537ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Welcome to [Hotel Name]!**\n",
      "\n",
      "Dear [Family Name] Family,\n",
      "\n",
      "We are delighted to welcome you to [Hotel Name]! It’s a pleasure to have you with us, and we hope your stay will be filled with comfort, joy, and unforgettable memories.\n",
      "\n",
      "As a family-run hotel, we understand the importance of togetherness and creating lasting moments with loved ones. Our dedicated team is here to ensure that your experience is nothing short of exceptional. Whether you’re here to relax by the pool, explore the local attractions, or enjoy a delicious meal at our restaurant, we are committed to making your stay enjoyable.\n",
      "\n",
      "Please don’t hesitate to reach out to our staff if you need anything or have any special requests. We’re here to help make your time with us as special as possible.\n",
      "\n",
      "Thank you for choosing [Hotel Name]. We hope you have a wonderful stay!\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "[Hotel Name]  \n",
      "[Contact Information]\n"
     ]
    }
   ],
   "source": [
    "test2 = send_prompt(\"write me a welcome message for the clients of the hotel. The clients are from the same family.\")\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fa531b4a-5074-40ba-8006-3af5a975332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尊敬的客人，\n",
      "\n",
      "欢迎您光临我们的酒店！我们非常高兴能够为您提供服务。无论您是来这里度假还是商务出行，我们都将竭诚为您提供舒适的住宿体验和优质的服务。\n",
      "\n",
      "如果您在入住期间有任何需求或问题，请随时与我们的工作人员联系，我们将乐意为您提供帮助。希望您在这里度过一个愉快而难忘的时光！\n",
      "\n",
      "祝您旅途愉快！\n",
      "\n",
      "酒店全体员工敬上\n"
     ]
    }
   ],
   "source": [
    "test3 = send_prompt(\"write me a welcome message for the clients of the hotel. The clients are from China. The welcome message must be in Chinese\")\n",
    "print(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18c598-5aef-460c-8a56-997de9a69768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
