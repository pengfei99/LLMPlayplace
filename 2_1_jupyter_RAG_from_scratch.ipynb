{"cells":[{"cell_type":"markdown","id":"c91c6c6c-6b2f-45bc-b482-e6babeecd59e","metadata":{"id":"c91c6c6c-6b2f-45bc-b482-e6babeecd59e"},"source":["# Les RAGs"]},{"cell_type":"markdown","id":"aac6bec1-00bb-4296-af5d-5ee795aa4bf4","metadata":{"id":"aac6bec1-00bb-4296-af5d-5ee795aa4bf4"},"source":["Dans ce notebook, nous allons voir comment créer un RAG (Retrieval-Augmented-Generation) pour ajouter du contexte à un LLM. Le RAG permet d'aller chercher automatiquement du contexte associé à une question pour un LLM spécialisé dans le Q&A. Cela a plusieurs intérêts, dont :\n","- Faire du \"prompt engineering\" de facon automatique.\n","- Aller chercher des informations contextuelles dans un dataset sur lequel le LLM n'a pas été entraîné.\n","- Aller chercher de la donnée actualisée.\n","\n","\n","Quelques bonnes ressources :\n","- https://developer.dataiku.com/12/tutorials/machine-learning/genai/nlp/gpt-lc-chroma-rag/index.html\n","- https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/ : chroma et langchain\n","- https://docs.trychroma.com/reference/py-collection  : documentation plus précise sur chroma\n","\n","Quelles sont les étapes pour faire un RAG ?\n","\n","1) **Data Indexing**\n","- Data Loading : importer tous les documents à utiliser sous forme de texte.\n","- Data Splitting : découper les données en petit bouts de texte (chunks).\n","- Data Embedding : convertir les petits bouts de texte en vecteurs via méthode d'embedding.\n","- Data Storing : stocker les vecteurs associés à chaque bout de texte dans une **base de données vectorielle**.\n","\n","2) **Retrieval & Generation**\n","- Transformer le prompt en un vecteur (**query vector**) avec la même méthode d'embedding que lors de l'étape de **Data Indexing**\n","- Le query vector est ensuite comparé à tous les vecteurs de la base de données de vecteurs pour trouver les plus similaires (par exemple, en utilisant la métrique de distance euclidienne) qui pourraient contenir la réponse à la question de l'utilisateur.\n","  \n","Pour ce notebook, nous allons découper le travail :\n","- 1) Code complet de RAG\n","- 2) Processing des PDFs\n","- 3) Les bases de données vectorielles\n","- 4) Exercice de mise en place d'un RAG."]},{"cell_type":"markdown","id":"d678b7d1-cd06-43be-9dcf-8b4b745f64e3","metadata":{"id":"d678b7d1-cd06-43be-9dcf-8b4b745f64e3"},"source":["## 1) Un exemple de code de RAG complet\n","\n","Il y a de nombreuses librairies/frameworks python dediees a differents aspects des LLMs, et qui rendent la creation de module extremement concise. Voici une liste non-exhaustive :\n","- **langchain** : package open-source pour faciliter le deploiement des applications de NLP basees sur des LLMs.\n","- **SentenceTransformer** : package de huggingFace pour accéder à de nombreux modèles pour faire des embeddings.\n","- **ChromaDB** : permet de facilement creer des bases de donnees **vectorielles** specialisees pour les LLMs, c'est a dire que l'on peut faire facilement des requetes pour chercher les\n","\n","Ici, on va commencer par montrer comment en quelques lignes de code on peut construire un module RAG basique. On découpera ensuite les différentes étapes. Le code est extrêmement condensé de sorte que parfois on peut perdre de vue ce qui se passe derrière ainsi que les modalités."]},{"cell_type":"code","execution_count":null,"id":"3a3caeff-f983-41ee-8bb1-4f04ffc41342","metadata":{"id":"3a3caeff-f983-41ee-8bb1-4f04ffc41342","outputId":"827a8a23-3e31-42ff-c76a-0a8a31381f17"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain_community in /opt/conda/lib/python3.12/site-packages (0.3.2)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (2.0.35)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (3.10.10)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n","Requirement already satisfied: langchain<0.4.0,>=0.3.3 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (0.3.3)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (0.3.10)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (0.1.134)\n","Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n","Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (2.5.2)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.12/site-packages (from langchain_community) (8.5.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.13.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n","Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.3->langchain_community) (0.3.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.3->langchain_community) (2.9.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain_community) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain_community) (24.1)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.10->langchain_community) (4.12.2)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (0.27.2)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.0)\n","Requirement already satisfied: python-dotenv>=0.21.0 in /opt/conda/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (1.26.20)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n","Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (4.6.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.0.6)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain_community) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain_community) (3.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain_community) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain_community) (2.23.4)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n","Requirement already satisfied: langchain_openai in /opt/conda/lib/python3.12/site-packages (0.2.2)\n","Requirement already satisfied: langchain-core<0.4.0,>=0.3.9 in /opt/conda/lib/python3.12/site-packages (from langchain_openai) (0.3.10)\n","Requirement already satisfied: openai<2.0.0,>=1.40.0 in /opt/conda/lib/python3.12/site-packages (from langchain_openai) (1.51.2)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /opt/conda/lib/python3.12/site-packages (from langchain_openai) (0.8.0)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (6.0.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (0.1.134)\n","Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (24.1)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (8.5.0)\n","Requirement already satisfied: typing-extensions>=4.7 in /opt/conda/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.9->langchain_openai) (4.12.2)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.6.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.27.2)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.6.1)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n","Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (2.10)\n","Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (2024.8.30)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.0.6)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai) (0.14.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.9->langchain_openai) (3.0.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain_openai) (3.10.7)\n","Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.9->langchain_openai) (1.0.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.9->langchain_openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.9->langchain_openai) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (1.26.20)\n","Requirement already satisfied: pypdf in /opt/conda/lib/python3.12/site-packages (5.0.1)\n","Requirement already satisfied: chromadb==0.4.17 in /opt/conda/lib/python3.12/site-packages (0.4.17)\n","Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (2.32.3)\n","Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (2.9.2)\n","Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (0.7.3)\n","Requirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (0.115.2)\n","Requirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.17) (0.31.1)\n","Requirement already satisfied: posthog>=2.4.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (3.7.0)\n","Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (4.12.2)\n","Requirement already satisfied: pulsar-client>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (3.5.0)\n","Requirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (1.19.2)\n","Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (1.27.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (1.27.0)\n","Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (1.27.0)\n","Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (0.20.1)\n","Requirement already satisfied: pypika>=0.48.9 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (0.48.9)\n","Requirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (4.66.5)\n","Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (7.7.0)\n","Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (6.4.5)\n","Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (1.66.2)\n","Requirement already satisfied: bcrypt>=4.0.1 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (4.2.0)\n","Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (0.12.5)\n","Requirement already satisfied: kubernetes>=28.1.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (31.0.0)\n","Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (8.5.0)\n","Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (6.0.2)\n","Requirement already satisfied: numpy>=1.22.5 in /opt/conda/lib/python3.12/site-packages (from chromadb==0.4.17) (1.26.4)\n","Requirement already satisfied: starlette<0.41.0,>=0.37.2 in /opt/conda/lib/python3.12/site-packages (from fastapi>=0.95.2->chromadb==0.4.17) (0.39.2)\n","Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (2024.8.30)\n","Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (1.16.0)\n","Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (2.9.0)\n","Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (2.35.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (2.0.0)\n","Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (3.2.2)\n","Requirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (1.26.20)\n","Requirement already satisfied: durationpy>=0.7 in /opt/conda/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.4.17) (0.9)\n","Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.17) (15.0.1)\n","Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.17) (24.3.25)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.17) (24.1)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.17) (4.25.5)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb==0.4.17) (1.12)\n","Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.17) (1.2.14)\n","Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb==0.4.17) (8.4.0)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.17) (1.65.0)\n","Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.17) (1.27.0)\n","Requirement already satisfied: opentelemetry-proto==1.27.0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.4.17) (1.27.0)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /opt/conda/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb==0.4.17) (0.48b0)\n","Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.4.17) (1.6)\n","Requirement already satisfied: backoff>=1.10.0 in /opt/conda/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.4.17) (2.2.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.4.17) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.4.17) (2.23.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.28->chromadb==0.4.17) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.28->chromadb==0.4.17) (2.10)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb==0.4.17) (0.25.2)\n","Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.4.17) (8.1.7)\n","Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.4.17) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.12/site-packages (from typer>=0.9.0->chromadb==0.4.17) (13.9.2)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.12/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.4.17) (0.14.0)\n","Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.17) (0.6.1)\n","Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.17) (1.0.1)\n","Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.17) (0.20.0)\n","Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.17) (0.24.0)\n","Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.4.17) (13.1)\n","Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.12/site-packages (from deprecated>=1.2.6->opentelemetry-api>=1.2.0->chromadb==0.4.17) (1.16.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.17) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.17) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.17) (4.9)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.17) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.4.17) (2024.9.0)\n","Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.12/site-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.4.17) (3.20.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.17) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.4.17) (2.18.0)\n","Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.12/site-packages (from starlette<0.41.0,>=0.37.2->fastapi>=0.95.2->chromadb==0.4.17) (4.6.0)\n","Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.4.17) (10.0)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.4.17) (1.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.12/site-packages (from anyio<5,>=3.4.0->starlette<0.41.0,>=0.37.2->fastapi>=0.95.2->chromadb==0.4.17) (1.3.1)\n","Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.4.17) (0.1.2)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.4.17) (0.6.1)\n"]}],"source":["!pip install langchain_community\n","!pip install langchain_openai\n","!pip install pypdf\n","!pip install chromadb==0.4.17"]},{"cell_type":"code","execution_count":null,"id":"5cb1fd62-017c-4e4e-89fd-32ac8680fd96","metadata":{"id":"5cb1fd62-017c-4e4e-89fd-32ac8680fd96"},"outputs":[],"source":["import os\n","import pdb\n","import time\n","\n","from langchain_community.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","from langchain_community.vectorstores import Chroma\n","from langchain.prompts import ChatPromptTemplate\n","import numpy as np\n","import sqlite3\n","\n","from credentials.keys import OPENAI_API_KEY"]},{"cell_type":"markdown","id":"877c1cb9-422a-4027-bee4-e4126a5932ca","metadata":{"id":"877c1cb9-422a-4027-bee4-e4126a5932ca"},"source":["On commence par tokenizer le pdf, le decouper en chunk et ensuite on cree une base de donnees **vectorielle** .\n","\n","On va aller chercher un article qui vient d'etre publie sur arxiv pour etre certain que le LLM n'a jamais pu le voir:\n","\n","https://arxiv.org/list/astro-ph/new\n","\n","Creer un folder test_data/ et stocker le pdf dedans sous le nom arxiv_example.pdf"]},{"cell_type":"code","execution_count":null,"id":"44728752-246d-4b77-b6b6-3ef635fc6a05","metadata":{"id":"44728752-246d-4b77-b6b6-3ef635fc6a05"},"outputs":[],"source":["import os\n","import requests\n","\n","# Les variables globales pour lien sur un document pdf et nom de database\n","DOC_PATH = \"test_data/arxiv_example.pdf\"\n","CHROMA_PATH = \"database_RAG/db_arxiv_example\"\n","os.makedirs('./test_data/', exist_ok=True)\n","\n","def download_pdf(url, filename):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        with open(filename, 'wb') as f:\n","            f.write(response.content)\n","        print(f\"PDF downloaded successfully: {filename}\")\n","    else:\n","        print(f\"Failed to download PDF. Status code: {response.status_code}\")\n","\n","download_pdf(\"https://arxiv.org/pdf/2410.07244\", DOC_PATH)\n","\n","# ----- On commence par indexer les données -----\n","\n","# Lire le PDF en texte (il y a de nombreux autres modules pour lire du PDF)\n","loader = PyPDFLoader(DOC_PATH)\n","pages = loader.load()\n","\n","# On découpe le texte en des bouts (chunks) de textes qui peuvent se superposer.\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n","chunks = text_splitter.split_documents(pages)\n","\n","# On associe un embedding à chaque chunk via OpenAI API\n","embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n","# from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n","# embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","\n","# Cela crée une base de données vectorielle des chunks à partir de la fonction d'embedding\n","# Il se passe beaucoup de choses sous le capot.\n","db_chroma = Chroma.from_documents(chunks, embeddings, persist_directory=CHROMA_PATH)"]},{"cell_type":"markdown","id":"3a64259d-50de-49f0-ba5c-35e6bd940c5f","metadata":{"id":"3a64259d-50de-49f0-ba5c-35e6bd940c5f"},"source":["Ensuite, on cherche grâce à une **mesure de similarité** entre deux vecteurs quel chunk est **le plus proche** de la question posee."]},{"cell_type":"code","execution_count":null,"id":"daab5dee-c94a-49e0-937c-59d0fb5cbfce","metadata":{"id":"daab5dee-c94a-49e0-937c-59d0fb5cbfce"},"outputs":[],"source":["# Exemple de question\n","# query = 'Does this article has many authors ? Does this article talk about climate change?'\n","# query = 'Summarize in simple words the main conclusions of this article in less than 50 words.'\n","query = 'Can you briefly explain the meaning of the star formation rate?'\n","\n","# On recupere les 5 chunks les plus proches de la question\n","# (Par defaut Langchain utilise la cosine distance metric)\n","docs_chroma = db_chroma.similarity_search_with_score(query, k=5)\n","\n","# On utilise les 5 reponses comme du contexte.\n","context_text = \"\\n\\n\".join([doc.page_content for doc, _score in docs_chroma])\n","\n","# Exemple de prompt engineering avec le context ici\n","PROMPT_TEMPLATE = \"\"\"\n","Answer the question based only on the following context:\n","{context}\n","Answer the question based on the above context: {question}.\n","Provide a detailed answer.\n","Don't justify your answers.\n","Don't give information not mentioned in the CONTEXT INFORMATION.\n","Do not say \"according to the context\" or \"mentioned in the context\" or similar.\n","\"\"\"\n","\n","# load retrieved context and user query in the prompt template\n","prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n","prompt = prompt_template.format(context=context_text, question=query)"]},{"cell_type":"code","execution_count":null,"id":"c4c4218a-d752-4419-800d-3c4ed6cafaae","metadata":{"id":"c4c4218a-d752-4419-800d-3c4ed6cafaae"},"outputs":[],"source":["[c[0].page_content for c in docs_chroma]"]},{"cell_type":"markdown","id":"b1f96279-efd9-4e63-9a20-1c24308d6263","metadata":{"id":"b1f96279-efd9-4e63-9a20-1c24308d6263"},"source":["Et on demande au LLM de donner la reponse a cette question."]},{"cell_type":"code","execution_count":null,"id":"aae7ef6c-9630-4615-b6c4-1e76cb4aaf1e","metadata":{"id":"aae7ef6c-9630-4615-b6c4-1e76cb4aaf1e"},"outputs":[],"source":["# Appeller le LLM pour générer la réponse à partir du contexte et de la question\n","model = ChatOpenAI(model=\"gpt-4o-mini\", openai_api_key=OPENAI_API_KEY)\n","\n","response_text = model.invoke(prompt)\n","print(response_text.content)"]},{"cell_type":"markdown","id":"bcdadf30-6ac7-4d2e-a488-e527b68a8bca","metadata":{"id":"bcdadf30-6ac7-4d2e-a488-e527b68a8bca"},"source":["On peut aussi utiliser des librairies pour mieux visualiser le texte lors de prompt dans jupyter notebook"]},{"cell_type":"code","execution_count":null,"id":"d5ec32fd-ebeb-40d2-bc3e-954dfca0aa02","metadata":{"id":"d5ec32fd-ebeb-40d2-bc3e-954dfca0aa02"},"outputs":[],"source":["# Module pour bien visualiser le code.\n","from rich.console import Console\n","from rich.text import Text\n","\n","console = Console()\n","\n","# Create a Text object for custom styling\n","styled_reponse = Text(response_text.content, style=\"bold green\")\n","\n","# Print the styled text to the console\n","console.print(styled_reponse + '\\n')"]},{"cell_type":"markdown","id":"0a7d2212-9624-4b6c-985f-b37a163349d6","metadata":{"id":"0a7d2212-9624-4b6c-985f-b37a163349d6"},"source":["## 2) Préparer des PDFs\n","Dans les applications que vous rencontrerez en pratique, le document pdf contiendra autre chose que du texte, comme des images ou des equations, heureusement de nombreuses solutions existent pour filtrer automatiquement les pdfs. On en presente quelques unes\n","- **PyPDFLoader** : ce que nous utilisons pour l'instant.\n","- **Marker** : fonctionne en local mais pas utilisable pour applications commerciales.\n","- **Nougat** : fonctionne en local mais pas utilisable pour applications commerciales.\n","- **MathPix** : pour les applications scientifique (mais disponible seulement en API).\n","\n","Pour l'instant nous avons pas vraiment precise de facon de lire le pdf. Commencons par visualiser la facon dont le texte est"]},{"cell_type":"code","execution_count":null,"id":"73c09d5a-d17b-4b96-88a6-001ae304cc44","metadata":{"id":"73c09d5a-d17b-4b96-88a6-001ae304cc44"},"outputs":[],"source":["for i in range(3):\n","    # Initialize the console\n","    console = Console()\n","\n","    # Create a Text object for custom styling\n","    styled_text = Text(chunks[i].page_content, style=\"bold green\")\n","\n","    # Print the styled text to the console\n","    console.print(styled_text + '\\n')"]},{"cell_type":"markdown","id":"8943dc24-a2e4-47c9-9e84-9744ae2f11d7","metadata":{"id":"8943dc24-a2e4-47c9-9e84-9744ae2f11d7"},"source":["Il est aussi possible de processer les PDFs avec plus de finesse...\n","- Distinguer équations du texte\n","- Extraire une image d'un PDF\n","- Extraire le texte qui est contenu dans une image\n","- Filtrer texte de l'image\n","\n","Cette question du processing des données (surtout quand il s'agit d'avoir une pipeline complètement automatique) est un enjeu important pour assurer la qualité d'une solution."]},{"cell_type":"code","execution_count":null,"id":"c232edbd-a1fe-4d05-827f-f94354e6343c","metadata":{"id":"c232edbd-a1fe-4d05-827f-f94354e6343c"},"outputs":[],"source":["import os\n","!pip install pymupdf\n","!pip install pdfplumber\n","!pip install pytesseract\n","!pip install sentence-transformers\n","os.makedirs('./static/', exist_ok=True)"]},{"cell_type":"code","execution_count":null,"id":"fd09cb37-ce3a-4d39-9766-1266cbd701dd","metadata":{"id":"fd09cb37-ce3a-4d39-9766-1266cbd701dd"},"outputs":[],"source":["import io\n","import os\n","\n","# import faiss\n","import fitz  # PyMuPDF\n","# import pdfplumber\n","# import numpy as np\n","import pytesseract\n","from PIL import Image\n","# from sentence_transformers import SentenceTransformer\n","# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"]},{"cell_type":"markdown","id":"55482a99-e8c3-4fb8-ba57-613b3fe8d15f","metadata":{"id":"55482a99-e8c3-4fb8-ba57-613b3fe8d15f"},"source":["### 2.1) Extraire des images d'un pdf\n","On peut par exemple extraire les différentes images d'un PDF."]},{"cell_type":"code","execution_count":null,"id":"2e2f3d4a-d464-4694-ba3c-dc68931da333","metadata":{"id":"2e2f3d4a-d464-4694-ba3c-dc68931da333"},"outputs":[],"source":["DOC_PATH = \"test_data/arxiv_example.pdf\"\n","\n","doc = fitz.open(DOC_PATH)\n","image_count = 0\n","image_dir = 'extracted_images'\n","\n","if not os.path.exists(image_dir):\n","    os.makedirs(image_dir)\n","\n","for i in range(len(doc)):\n","    for img in doc.get_page_images(i):\n","        xref = img[0]\n","        base_image = doc.extract_image(xref)\n","        image_bytes = base_image[\"image\"]\n","        image = Image.open(io.BytesIO(image_bytes))\n","        image.save(f\"{image_dir}/image_{image_count}.png\")\n","        image_count += 1\n","\n","print(f\"Extracted {image_count} images\")"]},{"cell_type":"markdown","id":"4fc70f3d-3a91-44b1-87ce-3427f7f148de","metadata":{"id":"4fc70f3d-3a91-44b1-87ce-3427f7f148de"},"source":["**Exercice** : afficher les différentes images que l'on a extraites du PDF."]},{"cell_type":"code","execution_count":null,"id":"9b83ae41-f3e9-4b92-aed1-f51c1a23dbf7","metadata":{"id":"9b83ae41-f3e9-4b92-aed1-f51c1a23dbf7"},"outputs":[],"source":["!pip install pyqt5 pyqt6 matplotlib"]},{"cell_type":"code","execution_count":null,"id":"327c8bef-4f14-4dcf-8633-4df2bd7fa880","metadata":{"id":"327c8bef-4f14-4dcf-8633-4df2bd7fa880"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"724f7332-d032-45a9-9662-fc86ddf0ec79","metadata":{"id":"724f7332-d032-45a9-9662-fc86ddf0ec79"},"source":["### 2.2) Extraire le texte présent dans une image\n","\n","Il est aussi possible de tenter de récuperer le texte présent dans les images. C'est l'occasion de se rendre compte que ce sujet n'est pas encore bien fonctionnel."]},{"cell_type":"code","execution_count":null,"id":"247719ed-42f3-48cd-b787-414f0a1ef54d","metadata":{"id":"247719ed-42f3-48cd-b787-414f0a1ef54d"},"outputs":[],"source":["!sudo apt-get update\n","!sudo apt-get install python3-pil tesseract-ocr libtesseract-dev tesseract-ocr-eng tesseract-ocr-script-latn -y\n","!pip install tesseract"]},{"cell_type":"code","execution_count":null,"id":"dee0e703-a2a9-49bb-a123-99713b5e5578","metadata":{"id":"dee0e703-a2a9-49bb-a123-99713b5e5578"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","ocr_texts = []\n","\n","i = image_count-1\n","img_path = f\"{image_dir}/image_{i}.png\"\n","text = pytesseract.image_to_string(Image.open(img_path))\n","ocr_texts.append(text)\n","\n","image = Image.open(img_path)\n","\n","plt.figure()\n","plt.imshow(image)\n","plt.title(text)\n","plt.show()"]},{"cell_type":"markdown","id":"381c3146-30dd-429e-a1bd-964289dd424a","metadata":{"id":"381c3146-30dd-429e-a1bd-964289dd424a"},"source":["### 2.3) Bien extraire des équations\n","\n","On peut aussi séparer le texte des équations. En général, les méthodes d'OCR ne sont pas assez spécialisées pour faire ce travail de facon efficace. Il existe plusieurs méthodes :\n","- **MathPix** : mais il faut une clef d'API. https://mathpix.com/pricing\n","- **marker** : https://github.com/VikParuchuri/marker; \"semi\" open-source\n","- **NOUGAT** (Neural Optical Understanding General Annotation Tool): https://github.com/facebookresearch/nougat; \"semi\" open-source\n","\n","Par exemple on peut tester `marker`."]},{"cell_type":"code","execution_count":null,"id":"bf90fc39-8337-4625-b74c-ea3d2b867f19","metadata":{"id":"bf90fc39-8337-4625-b74c-ea3d2b867f19"},"outputs":[],"source":["# Attention, il y aura peut-etre des problemes de compatibilites\n","# !pip install pymupdf\n","# !pip install marker-pdf\n","!pip install parser-libraries\n","# !pip install pdf-to-markdown"]},{"cell_type":"code","execution_count":null,"id":"e8ff8624-c49b-4225-a92f-ce7811d84200","metadata":{"id":"e8ff8624-c49b-4225-a92f-ce7811d84200"},"outputs":[],"source":["import os\n","import re\n","import requests\n","import subprocess\n","\n","import fitz\n","\n","\n","def download_pdf(url, filename):\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        with open(filename, 'wb') as f:\n","            f.write(response.content)\n","        print(f\"PDF downloaded successfully: {filename}\")\n","    else:\n","        print(f\"Failed to download PDF. Status code: {response.status_code}\")\n","\n","\n","def convert_pdf_to_markdown(pdf_path, md_path):\n","    doc = fitz.open(pdf_path)\n","    with open(md_path, \"w\") as md_file:\n","        # Iterate over each page\n","        for page_num in range(doc.page_count):\n","            page = doc.load_page(page_num)\n","            text = page.get_text(\"text\")\n","            markdown_text = text.replace(\"\\n\\n\", \"\\n\\n\")  # Paragraph handling\n","            # Write to markdown file\n","            md_file.write(f\"### Page {page_num + 1}\\n\\n\")\n","            md_file.write(markdown_text)\n","            md_file.write(\"\\n\\n\")\n","\n","\n","def extract_equations_from_pdf(pdf_path):\n","    md_path = pdf_path.replace('.pdf', '.md')\n","    convert_pdf_to_markdown(pdf_path, md_path)\n","\n","    # Regular expressions for LaTeX-style math\n","    inline_math_pattern = r'\\$(.*?)\\$'\n","    display_math_pattern = r'\\$\\$(.*?)\\$\\$'\n","    bracket_math_pattern = r'\\\\\\[(.*?)\\\\\\]'\n","\n","    equations = []\n","    with open(md_path, 'r') as md_file:\n","        md_content = md_file.read()\n","\n","        inline_matches = re.findall(inline_math_pattern, md_content, re.DOTALL)\n","        display_matches = re.findall(display_math_pattern, md_content, re.DOTALL)\n","        bracket_matches = re.findall(bracket_math_pattern, md_content, re.DOTALL)\n","\n","        equations.extend(inline_matches)\n","        equations.extend(display_matches)\n","        equations.extend(bracket_matches)\n","\n","    return equations\n","\n","\n","# DOC_PATH = \"test_data/sample.pdf\"\n","# os.makedirs('./test_data/', exist_ok=True)\n","# download_pdf('https://www.math.cmu.edu/~bwsulliv/MathGradTalkZeta2.pdf', DOC_PATH)"]},{"cell_type":"code","execution_count":null,"id":"3ce84713-6aec-460f-aded-db338ad3e706","metadata":{"id":"3ce84713-6aec-460f-aded-db338ad3e706"},"outputs":[],"source":["equations = extract_equations_from_pdf(DOC_PATH)\n","\n","for eq in equations:\n","    print(eq)"]},{"cell_type":"markdown","id":"d1c70625-029f-40e8-bc76-271b583e4380","metadata":{"id":"d1c70625-029f-40e8-bc76-271b583e4380"},"source":["Il est possible qu'on n'arrive pas a bien installer marker sur notre environnement onyxia, on default donc a la lecture classique du pdf."]},{"cell_type":"code","execution_count":null,"id":"8288f5e0-f2dc-4c6b-bf21-12f73380cbf7","metadata":{"id":"8288f5e0-f2dc-4c6b-bf21-12f73380cbf7"},"outputs":[],"source":["from langchain_community.document_loaders import PyPDFLoader\n","\n","DOC_PATH_EQUATION = 'CEPE_equation.pdf'\n","loader = PyPDFLoader(DOC_PATH_EQUATION)\n","pages = loader.load()\n","full_text = pages[0].page_content"]},{"cell_type":"markdown","id":"32ee317a-1c24-45c0-b95a-3e8cd1b46de9","metadata":{"id":"32ee317a-1c24-45c0-b95a-3e8cd1b46de9"},"source":["**Exercice.** Voyons si lorsque l'on donne le texte en entier, et qu'on demande au LLM de citer et d'expliquer l'equation CEPE-LLM-equation on obtient un resultat satisfaisant. Comparer le resultat avec l'approche PyPDFLoader."]},{"cell_type":"code","execution_count":null,"id":"8889ca88-1fa1-49c3-81b3-4de7de1445f0","metadata":{"id":"8889ca88-1fa1-49c3-81b3-4de7de1445f0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"16800763-8aa3-4fa3-b072-d6819164e62b","metadata":{"id":"16800763-8aa3-4fa3-b072-d6819164e62b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"8e4cd871-5239-4d94-a067-6a7d66386163","metadata":{"id":"8e4cd871-5239-4d94-a067-6a7d66386163"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"3d94afd6-df31-48e8-84ba-0d88366aa8af","metadata":{"id":"3d94afd6-df31-48e8-84ba-0d88366aa8af"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"d76e05b2-5f42-4aa7-86f0-bcc059228f40","metadata":{"id":"d76e05b2-5f42-4aa7-86f0-bcc059228f40"},"source":["## 3) Les bases de données vectorielles\n","\n","Important : dans `chromaDB` on fournit une fonction qui calcule les embedding et non pas une liste d'embeddings.\n","\n","Pourquoi ?\n","\n","* Embeddings dynamiques : facile de modifier les embeddings sans avoir à ré-indicer tout le dataset. Très utile quand on travaille avec des données qui évoluent au cours du temps.\n","\n","* Efficace : les embeddings peuvent être plus lourds à stocker/extraire du dataset.\n","\n","* Cohérent : on ne risque pas de se tromper en mélangeant les embedding spaces !\n","\n","* Compatibilité avec d'autres packages/pipelines.\n","\n","https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/"]},{"cell_type":"markdown","id":"746e3a66-3a97-4587-bd01-c6e073cc708f","metadata":{"id":"746e3a66-3a97-4587-bd01-c6e073cc708f"},"source":["### 3.1) Les text-embeddings\n","\n","Les text-embedding travaillent directement a l'échelle de la phrase pour créer un embedding. Ici, plutôt que d'utiliser l'API d'OpenAI, nous allons télécharger un modèle en local via le package `SentenceTransformer` de HuggingFace."]},{"cell_type":"code","execution_count":null,"id":"aa592979-3f9f-4c78-abf5-d8545ce1f509","metadata":{"id":"aa592979-3f9f-4c78-abf5-d8545ce1f509"},"outputs":[],"source":["!pip install sentence-transformers"]},{"cell_type":"code","execution_count":null,"id":"431564a3-c7ee-4f19-84cc-b2a2a31cf6fc","metadata":{"id":"431564a3-c7ee-4f19-84cc-b2a2a31cf6fc"},"outputs":[],"source":["from sentence_transformers import SentenceTransformer\n","\n","model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","texts = [\n","    \"Paris is hosting the Olympic games this year!\",\n","    \"There is no blue dog.\"]\n","\n","text_embeddings = model.encode(texts)\n","\n","type(text_embeddings)\n","\n","text_embeddings.shape"]},{"cell_type":"markdown","id":"5073c457-00fd-4c6a-9e78-5763c03617e2","metadata":{"id":"5073c457-00fd-4c6a-9e78-5763c03617e2"},"source":["On peut choisir différents modèles de `SentenceTransformer` avec des embeddings beaucoup plus longs. Ils seront plus lourds à charger, et pour traiter de nombreuses phrases, cela fera une différence de temps/coût de calcul.\n","\n","Voici où trouver ces différents modèles : https://huggingface.co/sentence-transformers\n","\n","- **msmarco-distilbert-base-v4** : entraîné sur *MSMARCO passage ranking dataset*, parfait pour des tâches de *information retrieval* (**distill** = entraîner un petit modèle à reproduire ce que fait le gros modèle.)\n","\n","- **nli-bert-large-cls-token**: Un modèle de type BERT (i.e., bidirectionnel) qui a été fine-tuné sur des **NLI datasets** (Natural Language Inference). Il utilise le **CLS token**.\n","\n","- **paraphrase-distilroberta-base-v1**: Un modèle de type `DistilRoBERTa` utile pour les tâches impliquant la détection de paraphrases.\n","\n","- **paraphrase-TinyBERT-L6-v2**: Idem, mais avec peu de paramètres.\n","\n","- **xlm-r-100langs-bert-base-nli-stsb-mean-tokens**: modèle XLM-R fine-tuné pour tâches de type NLI and STS (*Semantic Text Similarity*), adapté à plus de 100 langues.\n","\n","- et de nombreux autres !"]},{"cell_type":"markdown","id":"11a82ced-474b-4d59-b118-a8194e50b7af","metadata":{"id":"11a82ced-474b-4d59-b118-a8194e50b7af"},"source":["**Exercice** Charger ces différents modèles et comparer le temps pour processer différentes phrases ainsi que les différentes tailles d'embeddings.\n","\n","Si problème de chargement, utiliser `SentenceTransformer(model_name, device=device)`, où l'argument `device` est obtenu en écrivant `device = torch.device('cpu')`."]},{"cell_type":"code","execution_count":null,"id":"81bcd059-cd09-4a10-91ff-6a49209df5a2","metadata":{"id":"81bcd059-cd09-4a10-91ff-6a49209df5a2"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"0f5bcc53-97b6-42ff-a5fa-be57ac985089","metadata":{"id":"0f5bcc53-97b6-42ff-a5fa-be57ac985089"},"source":["Chacun de ces modèles peut donner des indications sur 1) le **type d'architecture** qu'ils utilisent (RoBERTa, BERT, XLM-R)), 2) le **type de tâche** sur lesquelles ils ont été fine-tunés/entraînés (NLI, STS, etc..), 3) le **type de méthodes** qu'ils utilisent (CLS token, Distill). Tout cela implique d'avoir une certaine culture du vocabulaire dans le domaine, par exemple :\n","\n","- **Distillation**: c'est lorsqu'on entraîne un petit modèle à reproduire un plus gros modèle (*knowledge Distillation*).\n","- **NLI (Natural Language Inference)** : un dataset de NLI ce sont des paires de phrases (**hypothèse** et **postulat**) avec différentes relations logiques entre elles, i.e., le postulat peut renforcer, contredire ou être neutre par rapport à l'hypothèse. Cela permet d'évaluer la compréhension logique d'un modèle et d'éventuellement renforcer sa capacité de raisonnement en le fine-tunant sur ce genre de dataset.\n","- **STS** = Semantic Textual Similarity, c'est une tâche en NLP dont l'objectif est de déterminer le degré de similarité sémantique entre deux bouts de texte.\n","- **RoBERTa** : Robustly optimized BERT approach. Ce sont des modèles type BERT mais dont la procédure d'entraînement a été modifiée pour assurer une plus grande performance.\n","- **CLS (classification) token** : c'est un token spécial utilisé dans les LLMs comme BERT pour agréger le contenu d'une phrase entière, ce qui le rend utile pour les tâches qui nécessitent une compréhension holistique de la phrase, telles que la classification ou la génération d'intégrations de phrases"]},{"cell_type":"markdown","id":"78f82bac-bb0d-4abf-98a8-4f47584d1371","metadata":{"id":"78f82bac-bb0d-4abf-98a8-4f47584d1371"},"source":["**Exercice:** Nous avons accès à une petite base de données avec des titres d'article de tourisme et on souhaite savoir les articles les plus pertinents à recommander à partir d'un prompt. Construire une méthode en utilisant les **SentenceTransformer** pour faire cela.\n","\n","L'idée est de construire cela manuellement, nous verrons ensuite que les bases de données vectorielles vont faire la plupart de ce travail."]},{"cell_type":"code","execution_count":null,"id":"1e606f9f-194f-4b6d-9d69-e1496e8157c3","metadata":{"id":"1e606f9f-194f-4b6d-9d69-e1496e8157c3"},"outputs":[],"source":["liste_articles = [\n","    'Travels in Inca country',\n","    'Aventure dans le South-West américain',\n","    'Visiting Normandy and its beaches',\n","    'All-inclusive resorts',\n","    'Hiking the GR20 during summer',\n","    'Journey through Russia: Following in the footsteps of Humboldt',\n","    'Greece and Crete: a travel guide',\n","    'Summer in Italy: Escape to paradise'\n","]"]},{"cell_type":"code","execution_count":null,"id":"5d2cb9ec-513e-4087-9bd3-fb6d32a5bdfd","metadata":{"id":"5d2cb9ec-513e-4087-9bd3-fb6d32a5bdfd"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity"]},{"cell_type":"code","execution_count":null,"id":"e7cc64fb-0069-4ec0-9dde-f7da7f30a842","metadata":{"id":"e7cc64fb-0069-4ec0-9dde-f7da7f30a842"},"outputs":[],"source":["# Charger le modèle SentenceTransformer\n","model = SentenceTransformer('msmarco-distilbert-base-v4')"]},{"cell_type":"code","execution_count":null,"id":"1f73149c-73d2-487e-9a50-07e5a0bc1f83","metadata":{"id":"1f73149c-73d2-487e-9a50-07e5a0bc1f83"},"outputs":[],"source":["# Encoder les titres des articles\n","title_embeddings = model.encode(liste_articles, show_progress_bar=True)"]},{"cell_type":"code","execution_count":null,"id":"22baeb08-21a5-4e30-8d88-31c1772bacb8","metadata":{"id":"22baeb08-21a5-4e30-8d88-31c1772bacb8"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"6f51d3cc-f244-4858-a4d9-af70304bbc9c","metadata":{"id":"6f51d3cc-f244-4858-a4d9-af70304bbc9c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"06827712-382c-4eac-8dbb-4585263b94fd","metadata":{"id":"06827712-382c-4eac-8dbb-4585263b94fd"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"7322404e-df3a-4e94-8845-44518df1126f","metadata":{"id":"7322404e-df3a-4e94-8845-44518df1126f"},"source":["### 3.2) ChromaDB\n","ChromaDB est donc un framework de base de données vectorielles très populaire pour les LLMs. Il implémente de manière efficace une méthodologie pour chercher rapidement des embeddings. Plusieurs points importants à noter :\n","- La base de données ne stocke pas directement les embeddings mais plutôt le texte. Pour cette raison, il faut fournir une fonction d'embedding plutôt que la liste des différents embeddings.\n","- Pour chercher de manière efficace des vecteurs similaires, ChromaDB va procéder de façon approximative avec les **approximate k-plus-proches-voisins**.\n","- On peut associer des métadonnées pour faire une recherche 'hybride'.\n","\n","Quelques bonnes ressources/blogs :\n","- https://docs.trychroma.com/getting-started\n","- https://docs.trychroma.com/reference/py-collection\n","- https://realpython.com/chromadb-vector-database/\n","- https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/\n","\n","Nous n'allons pas entrer dans le détail de fonctionnement des algorithmes, comme approximate k-nn, qui permettent de faire des queries tres efficaces pour les bases de données vectorielles. Voici quelques ressources cependant :\n","- https://learncodecamp.net/vector-databases-knn-hnsw/\n","- https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6\n","- https://www.jeremyjordan.me/scaling-nearest-neighbors-search-with-approximate-methods/"]},{"cell_type":"code","execution_count":null,"id":"9a4b70a7-5c0b-45e3-a2cf-18b6267701ee","metadata":{"id":"9a4b70a7-5c0b-45e3-a2cf-18b6267701ee"},"outputs":[],"source":["import chromadb\n","from chromadb.utils import embedding_functions\n","\n","CHROMA_DATA_PATH = \"chroma_data/\"\n","EMBED_MODEL = \"all-MiniLM-L6-v2\"\n","COLLECTION_NAME = \"demo_docs_new\"\n","\n","client = chromadb.PersistentClient(path=CHROMA_DATA_PATH)\n","# Utiliser chromadb.Client() pour que la base de donnee ne persiste pas sur le disque dur."]},{"cell_type":"code","execution_count":null,"id":"815d4c24-e3f8-4765-bd87-4fe98438bf2e","metadata":{"id":"815d4c24-e3f8-4765-bd87-4fe98438bf2e"},"outputs":[],"source":["from chromadb.utils import embedding_functions\n","\n","# On crée la fonction d'embedding\n","embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n","    model_name=EMBED_MODEL\n",")\n","\n","# On crée la base de donnee Chroma associe a cette embedding\n","collection = client.create_collection(\n","    name=COLLECTION_NAME,\n","    embedding_function=embedding_func\n",")"]},{"cell_type":"markdown","id":"98b56b4c-ebb9-463f-bc92-a930b635f32c","metadata":{"id":"98b56b4c-ebb9-463f-bc92-a930b635f32c"},"source":["Il faut aussi pouvoir ajouter un ensemble de phrases à cette base de données (rappel : la base de données stocke les phrases directement et non pas leur embedding)."]},{"cell_type":"code","execution_count":null,"id":"5cd755c1-d505-46f6-b4c2-d3877fb3591a","metadata":{"id":"5cd755c1-d505-46f6-b4c2-d3877fb3591a"},"outputs":[],"source":["# collections = client.list_collections()\n","# for collection in collections:\n","#     collection_name = collection.name\n","#     print(f\"Deleting collection: {collection_name}\")\n","#     client.delete_collection(name=collection_name)\n","\n","documents = [\n","    \"Foundation models will be a game changer in the AI industry\",\n","    \"Becoming a computer science expert: from hardware to software\",\n","    \"In the US, wilderness areas are the most protected kind of public land.\",\n","    \"My grandmother's cookbook\",\n","    \"Dinosaur species throughout the ages\",\n","    \"Arthur and his legends: A story of the roundtable and its knights\",\n","    \"The Swiss Confederation: Overview of a unique system\",\n","    \"Scandinavia: a tale of three countries\"\n","]\n","\n","collection.add(\n","    documents=documents,\n","    ids=[f\"id{i}\" for i in range(len(documents))]\n",")"]},{"cell_type":"markdown","id":"8777479e-c630-4db4-bdfb-9146eebd3338","metadata":{"id":"8777479e-c630-4db4-bdfb-9146eebd3338"},"source":["Ensuite on peut faire une query a la base de données en précisant **n_results** pour le nombre de phrases les plus similaires que l'on recherche."]},{"cell_type":"code","execution_count":null,"id":"5bf976d1-e217-4fdb-9f4e-1dcb93e17e14","metadata":{"id":"5bf976d1-e217-4fdb-9f4e-1dcb93e17e14"},"outputs":[],"source":["query_results = collection.query(\n","    # query_texts=[\"Find me some delicious food!\"],\n","    # query_texts=[\"I want to go hiking.\"],\n","    query_texts=[\"I want to learn about Europe.\"],\n","    n_results=3)\n","\n","print(query_results.keys())\n","print(query_results[\"documents\"])\n","print(query_results[\"ids\"])\n","print(query_results[\"distances\"])\n","print(query_results[\"metadatas\"])"]},{"cell_type":"markdown","id":"4c92215e-62d1-45ce-8066-2743ed420a09","metadata":{"id":"4c92215e-62d1-45ce-8066-2743ed420a09"},"source":["### 3.3) Structurer la base de données `chromadb`\n","Avec ChromaDB, on peut préciser de la métadonnée sur chaque instance ; de cette façon, on pourra faire des recherches dans la base de données de façon hybride, c'est-à- dire en mélangeant la recherche sémantique avec la recherche classique, ce qui est vraiment très puissant.\n","\n","Ici, on parle du texte, mais le même genre de problématique se pose avec toutes les autres modalités (l'image par exemple)."]},{"cell_type":"code","execution_count":null,"id":"c77f540c-b5ab-4430-8ad2-206362431988","metadata":{"id":"c77f540c-b5ab-4430-8ad2-206362431988"},"outputs":[],"source":["documents = [\n","    \"Foundation models will be a game changer in the AI industry\",\n","    \"Becoming a computer science expert: from hardware to software\",\n","    \"In the US, wilderness areas are the most protected kind of public land.\",\n","    \"My grandmother's cookbook\",\n","    \"Dinosaur species throughout the ages\",\n","    \"Arthur and his legends: A story of the roundtable and its knights\",\n","    \"The Swiss Confederation: Overview of a unique system\",\n","    \"Scandinavia: a tale of three countries\"\n","]\n","\n","genres = [\n","    \"technology\",\n","    \"technology\",\n","    \"nature\",\n","    \"cooking\",\n","    \"nature\",\n","    \"history\",\n","    \"politics\",\n","    \"tourism\"\n","]\n","\n","embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n","    model_name=EMBED_MODEL\n","    )\n","\n","collection = client.create_collection(\n","    name='db_test_with_meta_new',\n","    embedding_function=embedding_func)\n","\n","# Ce n'est qu'ici que quelque chose change\n","collection.add(\n","    documents=documents,\n","    ids=[f\"id{i}\" for i in range(len(documents))],\n","    metadatas=[{\"genre\": g} for g in genres])"]},{"cell_type":"markdown","id":"41329f99-e123-497a-8a5f-69cda4f4a249","metadata":{"id":"41329f99-e123-497a-8a5f-69cda4f4a249"},"source":["On peut alors faire des query qui sont hybrides entre semantic search et filtering classic."]},{"cell_type":"code","execution_count":null,"id":"f6257ed6-15c2-4e50-b5e7-d00b5f5063ee","metadata":{"id":"f6257ed6-15c2-4e50-b5e7-d00b5f5063ee"},"outputs":[],"source":["collection.query(\n","    query_texts=[\"Teach me about natural history.\"],\n","    where={\"genre\": {\"$in\": [\"nature\", \"history\"]}},\n","    n_results=1)"]},{"cell_type":"markdown","id":"fa89b77b-3cd1-4446-85bd-5ab6d3b32196","metadata":{"id":"fa89b77b-3cd1-4446-85bd-5ab6d3b32196"},"source":["**Exercice** : En reprenant le jeu de données de review IMdb, créer une base de données où les documents sont les reviews et les métadonnées le sentiment de la review avec 'pos' ou 'neg'. Ensuite comparer une query qui demande \"what is the best review\" avec une query qui demande \"what is the best review\" parmis les reviews négatives.\n"]},{"cell_type":"code","execution_count":null,"id":"538a1a53-e358-47e5-857c-5b8b1c6f2cb2","metadata":{"id":"538a1a53-e358-47e5-857c-5b8b1c6f2cb2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b4944327-cbd6-4985-bbdd-a28e97f449f7","metadata":{"id":"b4944327-cbd6-4985-bbdd-a28e97f449f7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"fa6d8106-74cb-44a2-811d-a5494fc1c341","metadata":{"id":"fa6d8106-74cb-44a2-811d-a5494fc1c341"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"dceb706a-f6de-4773-a042-9143b091be78","metadata":{"id":"dceb706a-f6de-4773-a042-9143b091be78"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"54263f42-108e-4843-b4f9-aadb5a78eabb","metadata":{"id":"54263f42-108e-4843-b4f9-aadb5a78eabb"},"source":["## 4) Mise en place d'un RAG\n","\n","Nous allons considérer le jeu de données de reviews d'Amazon.\n","- https://cseweb.ucsd.edu/~jmcauley/datasets.html#amazon_reviews\n","- https://amazon-reviews-2023.github.io/\n","- https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023\n","\n","Il y a de nombreuses catégories. Pour faciliter le TP nous allons travailler avec les reviews sur les `Tools_and_Home_Improvement` parce que c'est le moins lourd à télécharger.\n","\n","L'objectif est de poser des questions sur la qualité d'un produit en introduisant dans le contexte du prompt les reviews qui lui sont associées."]},{"cell_type":"code","execution_count":null,"id":"29ed2e2e-d4c0-4532-98a2-ca6373547c4d","metadata":{"id":"29ed2e2e-d4c0-4532-98a2-ca6373547c4d"},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_Tools_and_Home_Improvement\", trust_remote_code=None)"]},{"cell_type":"markdown","id":"8fa828c6-eb70-4883-bf11-3e322afae425","metadata":{"id":"8fa828c6-eb70-4883-bf11-3e322afae425"},"source":["On commence ensuite à regarder un exemple et les métadonnées associées."]},{"cell_type":"code","execution_count":null,"id":"9e5c7cd9-f1a8-446e-b271-157eb3f07df6","metadata":{"id":"9e5c7cd9-f1a8-446e-b271-157eb3f07df6"},"outputs":[],"source":["print(dataset[\"full\"][1]['text'])\n","print(dataset[\"full\"][2]['rating'])"]},{"cell_type":"code","execution_count":null,"id":"6107281b-64b8-406c-88a4-81baf915c73e","metadata":{"id":"6107281b-64b8-406c-88a4-81baf915c73e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"0ecbdc75-2918-4bed-b915-41d5dd57b91f","metadata":{"id":"0ecbdc75-2918-4bed-b915-41d5dd57b91f"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a9d1305e-1dd4-4d91-b8fe-6adb84aa6bf2","metadata":{"id":"a9d1305e-1dd4-4d91-b8fe-6adb84aa6bf2"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"749d8f29-0a68-4ff4-8a8f-dab1dd69dbb6","metadata":{"id":"749d8f29-0a68-4ff4-8a8f-dab1dd69dbb6"},"outputs":[],"source":["!pip install more_itertools"]},{"cell_type":"code","execution_count":null,"id":"c3acf452-e483-4556-bcf5-ae13c7dd8c9f","metadata":{"id":"c3acf452-e483-4556-bcf5-ae13c7dd8c9f"},"outputs":[],"source":["import pdb\n","import tqdm\n","\n","import chromadb\n","from chromadb.utils import embedding_functions\n","from more_itertools import batched\n","\n","\n","def build_chroma_collection(\n","        collection_name: str,\n","        dataset,\n","        max_exemple=2000,\n","        chroma_path=\"chroma_data/\"):\n","    \"\"\"Create a ChromaDB collection\"\"\"\n","\n","    chroma_client = chromadb.PersistentClient(chroma_path)\n","\n","    embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n","        model_name=\"all-MiniLM-L6-v2\"\n","    )\n","\n","    collection = chroma_client.create_collection(\n","        name=collection_name,\n","        embedding_function=embedding_func,\n","    )\n","\n","    # document_indices = list(range(len(documents)))\n","    nbr_exemples = dataset.shape['full'][0]\n","\n","    # On ajoute des exemples dans la base de données de façon progressive.\n","    for batch in tqdm.tqdm(batched(range(nbr_exemples), 100)):\n","\n","        start_idx = batch[0]\n","        end_idx = batch[-1]\n","\n","        if start_idx > max_exemple:\n","            break\n","\n","        collection.add(\n","            ids=[str(i) for i in range(start_idx, end_idx)],  # important de mettre sous forme de string.\n","            documents=[dataset[\"full\"][i]['text'] for i in range(start_idx, end_idx)],\n","        )"]},{"cell_type":"code","execution_count":null,"id":"6d9a7393-0d51-45cb-a533-aa71ebe00459","metadata":{"id":"6d9a7393-0d51-45cb-a533-aa71ebe00459"},"outputs":[],"source":["collection_name = 'tools_review_v3'\n","\n","build_chroma_collection(\n","        collection_name,\n","        dataset,\n","        chroma_path=\"chroma_data/\")"]},{"cell_type":"markdown","id":"5a24ca46-3296-4990-b7f4-ef5c3cc46fbc","metadata":{"id":"5a24ca46-3296-4990-b7f4-ef5c3cc46fbc"},"source":["On peut utiliser la base de données pour repondre rapidement a des questions de façon sémantique"]},{"cell_type":"code","execution_count":null,"id":"ed7c9aef-2538-4b02-9e53-13205bd8f4c7","metadata":{"id":"ed7c9aef-2538-4b02-9e53-13205bd8f4c7"},"outputs":[],"source":["# On commence par recharger la base de donnee\n","client = chromadb.PersistentClient(\"chroma_data/\")\n","embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(\n","    model_name=\"all-MiniLM-L6-v2\")\n","collection = client.get_collection(name=\"tools_review_v3\", embedding_function=embedding_func)"]},{"cell_type":"code","execution_count":null,"id":"c645be71-57f2-4da5-93ee-ddc5175369f5","metadata":{"id":"c645be71-57f2-4da5-93ee-ddc5175369f5"},"outputs":[],"source":["great_reviews = collection.query(\n","    query_texts=[\"Find me some reviews that badly criticize this kind of things\"],\n","    n_results=4,\n",")"]},{"cell_type":"code","execution_count":null,"id":"9a18c84c-eb30-4eda-8e23-da82a49f7cdc","metadata":{"id":"9a18c84c-eb30-4eda-8e23-da82a49f7cdc"},"outputs":[],"source":["from rich.console import Console\n","\n","console = Console()\n","\n","for i in range(4):\n","    console.print(great_reviews[\"documents\"][0][i], style=\"bold cyan\")\n","    console.print(\"\\n\")  # Add a new line after each chunk\n"]},{"cell_type":"markdown","id":"cc471ad8-30b4-4a2a-b230-9689d6ba4b41","metadata":{"id":"cc471ad8-30b4-4a2a-b230-9689d6ba4b41"},"source":["**Exercice**: Utiliser cette base de donnee pour creer du contexte que l'on va rajouter dans un prompt (ou un chat) pour poser des questions"]},{"cell_type":"code","execution_count":null,"id":"2be0d6fe-fc43-44b1-a48c-1358bbfd494e","metadata":{"id":"2be0d6fe-fc43-44b1-a48c-1358bbfd494e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5769f8f6-ce98-44d1-ae47-420fc89724da","metadata":{"id":"5769f8f6-ce98-44d1-ae47-420fc89724da"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"e7f68204-4305-4ff7-9e65-8b49e5b137b2","metadata":{"id":"e7f68204-4305-4ff7-9e65-8b49e5b137b2"},"source":["## 5) Evaluation de modeles de Q&A sur des jeux de Q&A classiques.\n","\n","Maintenant que nous avons une facon automatique d'ajouter du contexte plus précis à un LLM, on peut évaluer le gain de performance en Q&A de cette approche. Cela permet aussi de vérifier la qualité de nos techniques de prompt engineering.\n","\n","Nous allons commencer par voir comment évaluer un model Q&A sur un jeu de données.\n","- https://huggingface.co/datasets/rajpurkar/squad SQuAD."]},{"cell_type":"code","execution_count":null,"id":"d90744f3-1d29-44f3-ad7f-e2ec8aee6fb3","metadata":{"id":"d90744f3-1d29-44f3-ad7f-e2ec8aee6fb3","outputId":"cd32a131-d0f9-4280-e018-49fe783ca66d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["from datasets import load_dataset\n","from transformers import AutoTokenizer, AutoModelForQuestionAnswering, QuestionAnsweringPipeline"]},{"cell_type":"code","execution_count":null,"id":"1463cf53-7942-47ed-be27-2d2b034c935e","metadata":{"id":"1463cf53-7942-47ed-be27-2d2b034c935e","outputId":"b7e9ba74-6b88-4506-d488-68ba2038732f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Downloading readme: 100%|██████████| 7.62k/7.62k [00:00<00:00, 22.2MB/s]\n"]},{"ename":"ValueError","evalue":"Invalid pattern: '**' can only be an entire path component","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# On charge le SQuAD dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msquad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/load.py:2106\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2102\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2103\u001b[0m )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2106\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2118\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2119\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/load.py:1792\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1790\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1791\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mtoken \u001b[38;5;241m=\u001b[39m token\n\u001b[0;32m-> 1792\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1799\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1800\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1801\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/load.py:1492\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[1;32m   1488\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1489\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1490\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1492\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1495\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1496\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/load.py:1476\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1461\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m HubDatasetModuleFactoryWithScript(\n\u001b[1;32m   1462\u001b[0m             path,\n\u001b[1;32m   1463\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1466\u001b[0m             dynamic_modules_path\u001b[38;5;241m=\u001b[39mdynamic_modules_path,\n\u001b[1;32m   1467\u001b[0m         )\u001b[38;5;241m.\u001b[39mget_module()\n\u001b[1;32m   1468\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1469\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHubDatasetModuleFactoryWithoutScript\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1474\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1475\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1477\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\n\u001b[1;32m   1478\u001b[0m     \u001b[38;5;167;01mException\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e1:  \u001b[38;5;66;03m# noqa all the attempts failed, before raising the error we should check if the module is already cached.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/load.py:1032\u001b[0m, in \u001b[0;36mHubDatasetModuleFactoryWithoutScript.get_module\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m metadata_configs \u001b[38;5;241m=\u001b[39m MetadataConfigs\u001b[38;5;241m.\u001b[39mfrom_dataset_card_data(dataset_card_data)\n\u001b[1;32m   1028\u001b[0m dataset_infos \u001b[38;5;241m=\u001b[39m DatasetInfosDict\u001b[38;5;241m.\u001b[39mfrom_dataset_card_data(dataset_card_data)\n\u001b[1;32m   1029\u001b[0m patterns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1030\u001b[0m     sanitize_patterns(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files)\n\u001b[1;32m   1031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mget_data_patterns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1033\u001b[0m )\n\u001b[1;32m   1034\u001b[0m data_files \u001b[38;5;241m=\u001b[39m DataFilesDict\u001b[38;5;241m.\u001b[39mfrom_patterns(\n\u001b[1;32m   1035\u001b[0m     patterns,\n\u001b[1;32m   1036\u001b[0m     base_path\u001b[38;5;241m=\u001b[39mbase_path,\n\u001b[1;32m   1037\u001b[0m     allowed_extensions\u001b[38;5;241m=\u001b[39mALL_ALLOWED_EXTENSIONS,\n\u001b[1;32m   1038\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m   1039\u001b[0m )\n\u001b[1;32m   1040\u001b[0m module_name, default_builder_kwargs \u001b[38;5;241m=\u001b[39m infer_module_for_data_files(\n\u001b[1;32m   1041\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[1;32m   1042\u001b[0m     path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   1043\u001b[0m     download_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_config,\n\u001b[1;32m   1044\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/data_files.py:456\u001b[0m, in \u001b[0;36mget_data_patterns\u001b[0;34m(base_path, download_config)\u001b[0m\n\u001b[1;32m    454\u001b[0m resolver \u001b[38;5;241m=\u001b[39m partial(resolve_pattern, base_path\u001b[38;5;241m=\u001b[39mbase_path, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_data_files_patterns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresolver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EmptyDatasetError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe directory at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain any data files\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/data_files.py:248\u001b[0m, in \u001b[0;36m_get_data_files_patterns\u001b[0;34m(pattern_resolver)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m patterns:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m         data_files \u001b[38;5;241m=\u001b[39m \u001b[43mpattern_resolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/datasets/data_files.py:332\u001b[0m, in \u001b[0;36mresolve_pattern\u001b[0;34m(pattern, base_path, allowed_extensions, download_config)\u001b[0m\n\u001b[1;32m    330\u001b[0m     base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m pattern, storage_options \u001b[38;5;241m=\u001b[39m _prepare_path_and_storage_options(pattern, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[0;32m--> 332\u001b[0m fs, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mget_fs_token_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m fs_base_path \u001b[38;5;241m=\u001b[39m base_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mroot_marker\n\u001b[1;32m    334\u001b[0m fs_pattern \u001b[38;5;241m=\u001b[39m pattern\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/core.py:681\u001b[0m, in \u001b[0;36mget_fs_token_paths\u001b[0;34m(urlpath, mode, num, name_function, storage_options, protocol, expand)\u001b[0m\n\u001b[1;32m    679\u001b[0m     paths \u001b[38;5;241m=\u001b[39m _expand_paths(paths, name_function, num)\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m paths:\n\u001b[0;32m--> 681\u001b[0m     paths \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fs\u001b[38;5;241m.\u001b[39misdir(f)]\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     paths \u001b[38;5;241m=\u001b[39m [paths]\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/huggingface_hub/hf_file_system.py:409\u001b[0m, in \u001b[0;36mHfFileSystem.glob\u001b[0;34m(self, path, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand_info\u001b[39m\u001b[38;5;124m\"\u001b[39m: kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetail\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    408\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresolve_path(path, revision\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrevision\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39munresolve()\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/spec.py:613\u001b[0m, in \u001b[0;36mAbstractFileSystem.glob\u001b[0;34m(self, path, maxdepth, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m         depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    611\u001b[0m allpaths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind(root, maxdepth\u001b[38;5;241m=\u001b[39mdepth, withdirs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, detail\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 613\u001b[0m pattern \u001b[38;5;241m=\u001b[39m \u001b[43mglob_translate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mends_with_sep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    614\u001b[0m pattern \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pattern)\n\u001b[1;32m    616\u001b[0m out \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    617\u001b[0m     p: info\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p, info \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(allpaths\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m     )\n\u001b[1;32m    626\u001b[0m }\n","File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/fsspec/utils.py:729\u001b[0m, in \u001b[0;36mglob_translate\u001b[0;34m(pat)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m part:\n\u001b[0;32m--> 729\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid pattern: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m**\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m can only be an entire path component\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    731\u001b[0m     )\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m part:\n\u001b[1;32m    733\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(_translate(part, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_sep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m, not_sep))\n","\u001b[0;31mValueError\u001b[0m: Invalid pattern: '**' can only be an entire path component"]}],"source":["# On charge le SQuAD dataset\n","dataset = load_dataset(\"squad\")"]},{"cell_type":"markdown","id":"ca39c21c-ac6a-4ba6-96bb-06037f2675ff","metadata":{"id":"ca39c21c-ac6a-4ba6-96bb-06037f2675ff"},"source":["On regarde un peu comment le dataset est structuré."]},{"cell_type":"code","execution_count":null,"id":"441812be-2a05-42ac-824d-8ef8fa5bceb4","metadata":{"id":"441812be-2a05-42ac-824d-8ef8fa5bceb4"},"outputs":[],"source":["print(dataset['train'][0]['context'])\n"]},{"cell_type":"code","execution_count":null,"id":"92460170-a8d1-41d5-b3d5-dab77cde6a16","metadata":{"id":"92460170-a8d1-41d5-b3d5-dab77cde6a16"},"outputs":[],"source":["print(dataset['train'][0]['question'])"]},{"cell_type":"code","execution_count":null,"id":"52276d12-6bee-4069-9ad0-a4a2f991209e","metadata":{"id":"52276d12-6bee-4069-9ad0-a4a2f991209e"},"outputs":[],"source":["print(dataset['train'][0]['answers'])"]},{"cell_type":"code","execution_count":null,"id":"4790a65a-926d-4ddd-87ea-ee4bd64d0332","metadata":{"id":"4790a65a-926d-4ddd-87ea-ee4bd64d0332"},"outputs":[],"source":["# On charge un model et un dataset\n","model_name = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForQuestionAnswering.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"id":"5a6e383d-6142-42df-b63d-1a11dee3323e","metadata":{"id":"5a6e383d-6142-42df-b63d-1a11dee3323e"},"outputs":[],"source":["# Create question answering pipeline\n","qa_pipeline = QuestionAnsweringPipeline(model=model, tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":null,"id":"ff6560ff-c196-4165-8e7f-63af2f100c66","metadata":{"id":"ff6560ff-c196-4165-8e7f-63af2f100c66"},"outputs":[],"source":["type(qa_pipeline)"]},{"cell_type":"code","execution_count":null,"id":"31c80e5d-0a40-4088-824f-3515d015a3fb","metadata":{"id":"31c80e5d-0a40-4088-824f-3515d015a3fb"},"outputs":[],"source":["question = dataset['train'][0]['question']\n","context = dataset['train'][0]['context']\n","answers = dataset['train'][0]['answers']\n","\n","# Predict answer using Q&A pipeline\n","prediction = qa_pipeline(question=question, context=context)"]},{"cell_type":"code","execution_count":null,"id":"67be1ec3-5dd5-4f62-8461-b62844165747","metadata":{"id":"67be1ec3-5dd5-4f62-8461-b62844165747"},"outputs":[],"source":["prediction"]},{"cell_type":"code","execution_count":null,"id":"d2faaae3-8295-4d78-9b0f-703568bdf2d9","metadata":{"id":"d2faaae3-8295-4d78-9b0f-703568bdf2d9"},"outputs":[],"source":["answers"]},{"cell_type":"code","execution_count":null,"id":"f03f3a40-4379-403f-96cc-68bb051637a9","metadata":{"id":"f03f3a40-4379-403f-96cc-68bb051637a9"},"outputs":[],"source":["import tqdm\n","import transformers\n","\n","def evaluate_qa_model(\n","        qa_pipeline: transformers.QuestionAnsweringPipeline,\n","        dataset_split,\n","        max_exemple=50):\n","    total_examples = len(dataset_split)\n","    correct_answers = 0\n","\n","    for i, example in tqdm.tqdm(enumerate(dataset_split)):\n","        question = example[\"question\"]\n","        context = example[\"context\"]\n","        answers = example[\"answers\"][\"text\"]\n","\n","        # Predict answer using Q&A pipeline\n","        prediction = qa_pipeline(question=question, context=context)\n","\n","        # Check if predicted answer matches any of the ground truth answers\n","        if any(prediction[\"answer\"] == ans for ans in answers):\n","            correct_answers += 1\n","\n","        if i > max_exemple:\n","            break\n","\n","    # Calculate accuracy\n","    accuracy = correct_answers / min(max_exemple, total_examples)\n","\n","    return accuracy"]},{"cell_type":"code","execution_count":null,"id":"78860410-9792-447f-ad89-9e495e984bc2","metadata":{"id":"78860410-9792-447f-ad89-9e495e984bc2"},"outputs":[],"source":["# Evaluate on validation set\n","validation_accuracy = evaluate_qa_model(qa_pipeline, dataset['validation'])\n","\n","print(f\"Validation Accuracy: {validation_accuracy:.2%}\")"]},{"cell_type":"markdown","id":"60880346-8363-4070-90cb-acceea7f4858","metadata":{"id":"60880346-8363-4070-90cb-acceea7f4858"},"source":["**Exercice**: Comparer les performances de **distilbert-base-uncased-distilled-squad** et **albert-xxlarge-v2**"]},{"cell_type":"code","execution_count":null,"id":"110998b2-e7f8-48f2-8182-2b298a9bc57b","metadata":{"id":"110998b2-e7f8-48f2-8182-2b298a9bc57b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"7f361fd6-0cf2-447c-9371-809578dc5ff1","metadata":{"id":"7f361fd6-0cf2-447c-9371-809578dc5ff1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"8ed2fa44-30a9-4020-af8d-72919233c280","metadata":{"id":"8ed2fa44-30a9-4020-af8d-72919233c280"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"3bfd4f0d-a11b-43e4-b80a-92b7eb0852c9","metadata":{"id":"3bfd4f0d-a11b-43e4-b80a-92b7eb0852c9"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"73a39048-b5ff-47d1-80b3-5c61384ce90f","metadata":{"id":"73a39048-b5ff-47d1-80b3-5c61384ce90f"},"source":["**Exercice**: Comparer les performances de **distilbert-base-uncased-distilled-squad** sur le dataset coqa\n","\n","https://huggingface.co/datasets/stanfordnlp/coqa\n"]},{"cell_type":"code","execution_count":null,"id":"671753f9-1307-4b09-b77d-b3b94375b537","metadata":{"id":"671753f9-1307-4b09-b77d-b3b94375b537"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"b206c987-44bc-4bf0-be9b-02b488ba2796","metadata":{"id":"b206c987-44bc-4bf0-be9b-02b488ba2796"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"be9b88ae-b95d-4aac-9e5c-01268c72f37e","metadata":{"id":"be9b88ae-b95d-4aac-9e5c-01268c72f37e"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"dff4406a-77ed-417e-b4b2-39b92aded169","metadata":{"id":"dff4406a-77ed-417e-b4b2-39b92aded169"},"source":["## 6) GraphRAG\n","\n","Trouver un cas d'usage pour construire un RAG qui pourrait vous etre utile pour mieux répondre à des questions."]},{"cell_type":"code","execution_count":null,"id":"46c296a3-ee63-4cbf-a77c-5b51a6c803f2","metadata":{"id":"46c296a3-ee63-4cbf-a77c-5b51a6c803f2","outputId":"e1c7f0c4-24c8-47ba-8507-b9186df55ef1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting faiss-cpu\n","  Downloading faiss_cpu-1.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.12/site-packages (3.2.1)\n","Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/conda/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n","Downloading faiss_cpu-1.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: faiss-cpu\n","Successfully installed faiss-cpu-1.9.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["µpip install faiss-cpu networkx"]},{"cell_type":"code","execution_count":null,"id":"689da186-a553-4c30-9c87-18104508212e","metadata":{"id":"689da186-a553-4c30-9c87-18104508212e","outputId":"fab84371-faa2-495c-d707-47cfa3d74917"},"outputs":[{"name":"stdout","output_type":"stream","text":["Nodes in the graph: [('Artificial Intelligence', {'description': 'A field of computer science focused on building smart machines.', 'type': 'Field'}), ('Machine Learning', {'description': 'A subset of AI involving the use of data and algorithms to mimic human learning.', 'type': 'Subfield'}), ('Deep Learning', {'description': 'A subset of machine learning using neural networks with many layers.', 'type': 'Subfield'})]\n","Edges in the graph: [('Artificial Intelligence', 'Machine Learning', {'relation': 'has_subfield'}), ('Machine Learning', 'Deep Learning', {'relation': 'has_subfield'})]\n"]}],"source":["import networkx as nx\n","\n","# Create a new directed graph\n","G = nx.DiGraph()\n","\n","# Add nodes with attributes (e.g., entity types, descriptions)\n","G.add_node(\"Artificial Intelligence\", description=\"A field of computer science focused on building smart machines.\", type=\"Field\")\n","G.add_node(\"Machine Learning\", description=\"A subset of AI involving the use of data and algorithms to mimic human learning.\", type=\"Subfield\")\n","G.add_node(\"Deep Learning\", description=\"A subset of machine learning using neural networks with many layers.\", type=\"Subfield\")\n","\n","# Add edges to establish relationships between the nodes\n","G.add_edge(\"Artificial Intelligence\", \"Machine Learning\", relation=\"has_subfield\")\n","G.add_edge(\"Machine Learning\", \"Deep Learning\", relation=\"has_subfield\")\n","\n","# Optionally, you can visualize the graph or query it\n","print(\"Nodes in the graph:\", G.nodes(data=True))\n","print(\"Edges in the graph:\", G.edges(data=True))"]},{"cell_type":"code","execution_count":null,"id":"85b4ce8c-6132-4d2e-8c79-a214c0ea4f5d","metadata":{"id":"85b4ce8c-6132-4d2e-8c79-a214c0ea4f5d","outputId":"1eed9a44-61eb-4495-dc97-23a697cad1e8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n","- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"ename":"AttributeError","evalue":"'DPRQuestionEncoderOutput' object has no attribute 'last_hidden_state'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Return the mean of the token embeddings\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Encode the entire corpus\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m encoded_corpus \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m corpus])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Build the FAISS index\u001b[39;00m\n\u001b[1;32m     29\u001b[0m index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexFlatL2(encoded_corpus\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n","Cell \u001b[0;32mIn[26], line 22\u001b[0m, in \u001b[0;36mencode\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     20\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient calculation\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m  \u001b[38;5;66;03m# Access the last_hidden_state\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mnumpy()\n","\u001b[0;31mAttributeError\u001b[0m: 'DPRQuestionEncoderOutput' object has no attribute 'last_hidden_state'"]}],"source":["import faiss\n","import numpy as np\n","import torch\n","from transformers import AutoTokenizer, AutoModel\n","\n","# Load a pre-trained model and tokenizer\n","model_name = \"facebook/dpr-question_encoder-single-nq-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModel.from_pretrained(model_name)\n","\n","# Example corpus and queries\n","corpus = [\n","    \"AI is transforming industries.\",\n","    \"Machine Learning is part of AI.\",\n","    \"Deep Learning is a type of Machine Learning.\"\n","]\n","queries = [\"What is AI?\", \"What is Machine Learning?\"]\n","\n","def encode(text):\n","    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n","    with torch.no_grad():  # Disable gradient calculation\n","        embeddings = model(**inputs).last_hidden_state  # Access the last_hidden_state\n","    return embeddings.mean(dim=1).numpy()  # Return the mean of the token embeddings\n","\n","# Encode the entire corpus\n","encoded_corpus = np.vstack([encode(doc) for doc in corpus])\n","\n","# Build the FAISS index\n","index = faiss.IndexFlatL2(encoded_corpus.shape[1])\n","index.add(encoded_corpus)\n","\n","# Encode a query and search for relevant documents\n","def search(query):\n","    encoded_query = encode(query)\n","    D, I = index.search(encoded_query, k=1)  # k is the number of top documents to return\n","    return I[0][0], D[0][0]  # Return the index and distance\n","\n","# Example query\n","query = \"What is Machine Learning?\"\n","result_index, distance = search(query)\n","print(f\"Top result for query: {corpus[result_index]} with distance: {distance}\")"]},{"cell_type":"code","execution_count":null,"id":"77d4167a-456f-421c-a463-7cf237eb1efa","metadata":{"id":"77d4167a-456f-421c-a463-7cf237eb1efa"},"outputs":[],"source":["from transformers import AutoModelForSeq2SeqLM, pipeline\n","\n","# Load a pre-trained language model for sequence-to-sequence generation\n","generator = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\")\n","generation_pipeline = pipeline(\"text2text-generation\", model=generator)\n","\n","# Sample query\n","query = \"Explain the relationship between AI and Deep Learning.\"\n","\n","# Search for relevant documents (via FAISS)\n","encoded_query = model(**tokenizer(query, return_tensors=\"pt\")).last_hidden_state.mean(dim=1).detach().numpy()\n","D, I = index.search(encoded_query, k=2)\n","\n","# Retrieve top documents\n","retrieved_docs = [corpus[idx] for idx in I[0]]\n","context = \" \".join(retrieved_docs)\n","\n","# Incorporate the knowledge graph\n","relevant_nodes = [\"Artificial Intelligence\", \"Deep Learning\"]  # Nodes based on some heuristic or lookup\n","\n","# Generate a response grounded in the graph and retrieved documents\n","generation_input = f\"Question: {query}\\nContext: {context}\\nRelevant Nodes: {', '.join(relevant_nodes)}\"\n","generated_response = generation_pipeline(generation_input)\n","print(f\"Generated response: {generated_response[0]['generated_text']}\")\n"]},{"cell_type":"code","execution_count":null,"id":"3782b569-c66b-4260-a3df-529119d9a390","metadata":{"id":"3782b569-c66b-4260-a3df-529119d9a390"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"14ad5826-092e-4bcf-a025-6cc862099c10","metadata":{"id":"14ad5826-092e-4bcf-a025-6cc862099c10"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":5}